{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cff4yKYctHif",
        "6zhRZvgWVBHa"
      ],
      "authorship_tag": "ABX9TyO4qmvTGg2qARhhz2cjyTC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91309d0c232c44dfa3ef8d5548e1c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f99903d4baf4978b973f701c7d4d129",
              "IPY_MODEL_b399ea107d6f4f9cab89636ac52f96a8",
              "IPY_MODEL_a59e213e2c134b728ec97a3102301ee5"
            ],
            "layout": "IPY_MODEL_f5c03664bf66456eb0150d311420c8e8"
          }
        },
        "1f99903d4baf4978b973f701c7d4d129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002df19846694588bd9e739337a15cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfd0a2aac124c6ea732f93bbe9e0293",
            "value": "parakeet-tdt-0.6b-v2.nemo: 100%"
          }
        },
        "b399ea107d6f4f9cab89636ac52f96a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980cbcbc6fbc461792311a742e47072c",
            "max": 2472222720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a104e4c73a7344b9b1ff2f71cb0220b1",
            "value": 2472222720
          }
        },
        "a59e213e2c134b728ec97a3102301ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d272d9b1b040b8a5bfa84cb9771ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_1968a6ecebf64f4889e2f62c77d6eaf9",
            "value": " 2.47G/2.47G [00:16&lt;00:00, 69.9MB/s]"
          }
        },
        "f5c03664bf66456eb0150d311420c8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002df19846694588bd9e739337a15cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfd0a2aac124c6ea732f93bbe9e0293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "980cbcbc6fbc461792311a742e47072c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a104e4c73a7344b9b1ff2f71cb0220b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21d272d9b1b040b8a5bfa84cb9771ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1968a6ecebf64f4889e2f62c77d6eaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/runfish5/tiny-tutorials/blob/main/discord-transcription-bot/jupyter-notebooks/Discord_bot_notebook_Nvidia_CPU_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎙️✍️ Voice Transcription Bot"
      ],
      "metadata": {
        "id": "1Obg8bsgBwOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='00BBF9'> Step 1: 🚦 Run this for overall setup"
      ],
      "metadata": {
        "id": "cff4yKYctHif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install requirements\n",
        "%%capture\n",
        "'''\n",
        "This is more cumbersome than necessary, but\n",
        "this way it creates a requirements.txt\n",
        "which is desirable.\n",
        "'''\n",
        "\n",
        "content = \"\"\"py-cord\n",
        "python-dotenv\"\"\"\n",
        "# openai-whisper\"\"\" # openai-whisper is slow to install...\n",
        "# openai-whisper is not required if working with whisperx\n",
        "\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"requirements.txt has been created.\")\n",
        "\n",
        "!pip install -r ./requirements.txt\n",
        "!pip install PyNaCl\n",
        "!pip install nest_asyncio\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "!rm -rf /content/tiny-tutorials\n",
        "!git clone https://github.com/runfish5/tiny-tutorials.git\n"
      ],
      "metadata": {
        "id": "YY-6zMibneNr",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title script definitions\n",
        "\n",
        "# cur_asr_model = 'WHISPERX' # Go to: https://github.com/runfish5/tiny-tutorials/tree/main/discord-transcription-bot/jupyter-notebooks\n",
        "cur_asr_model = 'NVIDIA'     # Go to: https://github.com/runfish5/tiny-tutorials/tree/main/discord-transcription-bot/jupyter-notebooks\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "for jupyter notebook text:\n",
        "\n",
        "  00BBF9    -     Deep sky blue\n",
        "  00A115    -     Pigment green\n",
        "  00A6A6    -     Light sea green\n",
        "'''\n",
        "\n",
        "GREEN = \"\\033[92m\"\n",
        "YELLOW = \"\\033[93m\"\n",
        "BLUE = \"\\033[94m\"\n",
        "CYAN = \"\\033[96m\"\n",
        "RESET = \"\\033[0m\"\n",
        "MAGENTA = '\\033[35m'\n",
        "RED = '\\033[31m'\n",
        "ORANGE = \"\\033[38;5;208m\"\n",
        "\n",
        "\n",
        "RESET = '\\033[0m'"
      ],
      "metadata": {
        "id": "T9B-oBj_7EIG",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='00BBF9'> Step 2: 🔌 Turn on bot\n",
        "- Set your `DISCORD_BOT_TOKEN` in the first cell"
      ],
      "metadata": {
        "id": "bUmtkxL7wzuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import packages; Load environment variables\n",
        "import tempfile,  os, discord, asyncio, nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from pprint import pprint\n",
        "from dotenv import load_dotenv\n",
        "# import os\n",
        "# print(\"Environment variables:\", os.environ)\n",
        "\n",
        "%cd /content/tiny-tutorials/discord-transcription-bot\n",
        "\n",
        "env_content = \"\"\"DISCORD_BOT_TOKEN=...\n",
        "\"\"\"\n",
        "\n",
        "with open(\".env\", \"w\") as env_file:\n",
        "    env_file.write(env_content)\n",
        "\n",
        "!pwd\n",
        "load_dotenv()\n",
        "print(\"'.env' file loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyFWf8Q12U9W",
        "outputId": "b8642b3c-c77c-45cf-ef65-d3892c030abc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tiny-tutorials/discord-transcription-bot\n",
            "/content/tiny-tutorials/discord-transcription-bot\n",
            "'.env' file loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = os.getenv(\"DISCORD_BOT_TOKEN\")\n",
        "\n",
        "print(f\"'{token}'\")"
      ],
      "metadata": {
        "id": "KUOnfH0k0VtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5eb632f-264b-42f1-a4c5-284cca93cccf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'...'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get bot status\n",
        "\n",
        "def get_bot_status():\n",
        "  if 'bot_task' not in globals():\n",
        "\n",
        "      print(\"ERROR: bot_task not in globals()\")\n",
        "\n",
        "  elif bot_task.done():\n",
        "      print(\"Bot is NOT (!) running. 🛑\")\n",
        "  else:\n",
        "      print(\"Bot is RUNNING. 🔴 \")\n",
        "\n",
        "\n",
        "# get_bot_status()\n",
        "get_bot_status()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm1EzwTvxkhB",
        "outputId": "ae39707d-1429-47ae-eeea-2963f54ecc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot is NOT (!) running. 🛑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='magenta'> 📡 Run main.py and keep-alive task\n",
        "# (the fancy way)\n",
        "\n",
        "%cd /content\n",
        "exec(open(\"/content/tiny-tutorials/discord-transcription-bot/main.py\").read())\n",
        "\n",
        "# Global stop flag\n",
        "running = True\n",
        "\n",
        "async def keep_alive():\n",
        "    global running\n",
        "    while running:\n",
        "        await asyncio.sleep(1)  # Keep the loop alive without blocking\n",
        "\n",
        "# Start the bot and the keep-alive task\n",
        "loop            = asyncio.get_event_loop()\n",
        "bot_task        = loop.create_task(run_bot())         # `run_bot()` is defined in the `main.py`\n",
        "keep_alive_task = loop.create_task(keep_alive())\n",
        "\n",
        "get_bot_status()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb6N_VkC8sa-",
        "outputId": "c66782f8-48a1-4ee2-8ad9-e9f604b9291e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "This script is meant to be run from the notebook.\n",
            "Bot is RUNNING. 🔴 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='magenta'>bot: off-switch\n",
        "\n",
        "await bot.close()\n",
        "\n",
        "get_bot_status()\n",
        "'''\n",
        "Set the stop flag\n",
        "'''\n",
        "running = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytJKjyeV7a-o",
        "outputId": "9e1eda40-03b7-4a78-9a2c-45d956f9d64b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot is NOT (!) running. 🛑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 💾 zip it\n",
        "\n",
        "'''\n",
        "We zip it for downloading.\n",
        "(Google Colab doesn't support download and upload of directories.)\n",
        "'''\n",
        "from datetime import datetime\n",
        "\n",
        "current_date = datetime.now().strftime(\"%y%m%d\")\n",
        "\n",
        "base_zip_filename = f\"{current_date}_recordings.zip\"\n",
        "\n",
        "# Check if file exists and add version number if needed\n",
        "i = 1\n",
        "zip_filename = base_zip_filename\n",
        "while os.path.exists(zip_filename):\n",
        "    zip_filename = f\"{current_date}_recordings_{i}.zip\"\n",
        "    i += 1\n",
        "\n",
        "# Zip the recordings directory with the dated filename\n",
        "!zip -r {zip_filename} recordings\n",
        "\n",
        "print(f\"{MAGENTA}Created zip file: {zip_filename}{RESET}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa47a3f-b136-43a7-e451-86f011af708c",
        "id": "tmX8XSRpi8g9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: recordings/ (stored 0%)\n",
            "\u001b[35mCreated zip file: 250514_recordings.zip\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='00BBF9'>Step 3: ⚡ ASR /  Automatic Speech Recognition 🎙️✍️"
      ],
      "metadata": {
        "id": "6zhRZvgWVBHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZIw_g9GnxTz",
        "outputId": "f845a44a-74d6-4b15-857c-5b99aad6d5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://discordpy.readthedocs.io/en/latest/discord.html\n",
        "\n",
        "Direct for discord using javascript: https://github.com/Rei-x/discord-speech-recognition?tab=readme-ov-file"
      ],
      "metadata": {
        "id": "WG9fOijd2Naf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='00A115'>Nvidia ASR 2025\n",
        "1. install (~3 min 30 sec - model: parakeet-tdt-0.6b-v2)\n",
        "2. restart session"
      ],
      "metadata": {
        "id": "lzqbgl0tf1jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q"
      ],
      "metadata": {
        "id": "ieJWTMf-cSq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34f1be0-2886-4360-dcac-cfbd1e14527f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Wed May 14 17:20:20 2025\n",
            "Driver Version                            : 550.54.15\n",
            "CUDA Version                              : 12.4\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:03.0\n",
            "    Product Name                          : NVIDIA L4\n",
            "    Product Brand                         : NVIDIA\n",
            "    Product Architecture                  : Ada Lovelace\n",
            "    Display Mode                          : Enabled\n",
            "    Display Active                        : Disabled\n",
            "    Persistence Mode                      : Disabled\n",
            "    Addressing Mode                       : None\n",
            "    MIG Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Accounting Mode                       : Disabled\n",
            "    Accounting Mode Buffer Size           : 4000\n",
            "    Driver Model\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Serial Number                         : 1322623012199\n",
            "    GPU UUID                              : GPU-7c671bb6-21c5-b5ff-2b59-c905573c07cd\n",
            "    Minor Number                          : 0\n",
            "    VBIOS Version                         : 95.04.29.00.07\n",
            "    MultiGPU Board                        : No\n",
            "    Board ID                              : 0x3\n",
            "    Board Part Number                     : 900-2G193-6310-001\n",
            "    GPU Part Number                       : 27B8-895-A1\n",
            "    FRU Part Number                       : N/A\n",
            "    Module ID                             : 1\n",
            "    Inforom Version\n",
            "        Image Version                     : G193.0202.00.01\n",
            "        OEM Object                        : 2.1\n",
            "        ECC Object                        : 6.16\n",
            "        Power Management Object           : N/A\n",
            "    Inforom BBX Object Flush\n",
            "        Latest Timestamp                  : N/A\n",
            "        Latest Duration                   : N/A\n",
            "    GPU Operation Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    GPU C2C Mode                          : N/A\n",
            "    GPU Virtualization Mode\n",
            "        Virtualization Mode               : Pass-Through\n",
            "        Host VGPU Mode                    : N/A\n",
            "        vGPU Heterogeneous Mode           : N/A\n",
            "    GPU Reset Status\n",
            "        Reset Required                    : No\n",
            "        Drain and Reset Recommended       : N/A\n",
            "    GSP Firmware Version                  : N/A\n",
            "    IBMNPU\n",
            "        Relaxed Ordering Mode             : N/A\n",
            "    PCI\n",
            "        Bus                               : 0x00\n",
            "        Device                            : 0x03\n",
            "        Domain                            : 0x0000\n",
            "        Base Classcode                    : 0x3\n",
            "        Sub Classcode                     : 0x2\n",
            "        Device Id                         : 0x27B810DE\n",
            "        Bus Id                            : 00000000:00:03.0\n",
            "        Sub System Id                     : 0x16EE10DE\n",
            "        GPU Link Info\n",
            "            PCIe Generation\n",
            "                Max                       : 3\n",
            "                Current                   : 1\n",
            "                Device Current            : 1\n",
            "                Device Max                : 4\n",
            "                Host Max                  : N/A\n",
            "            Link Width\n",
            "                Max                       : 16x\n",
            "                Current                   : 16x\n",
            "        Bridge Chip\n",
            "            Type                          : N/A\n",
            "            Firmware                      : N/A\n",
            "        Replays Since Reset               : 0\n",
            "        Replay Number Rollovers           : 0\n",
            "        Tx Throughput                     : 0 KB/s\n",
            "        Rx Throughput                     : 0 KB/s\n",
            "        Atomic Caps Inbound               : N/A\n",
            "        Atomic Caps Outbound              : N/A\n",
            "    Fan Speed                             : N/A\n",
            "    Performance State                     : P8\n",
            "    Clocks Event Reasons\n",
            "        Idle                              : Active\n",
            "        Applications Clocks Setting       : Not Active\n",
            "        SW Power Cap                      : Not Active\n",
            "        HW Slowdown                       : Not Active\n",
            "            HW Thermal Slowdown           : Not Active\n",
            "            HW Power Brake Slowdown       : Not Active\n",
            "        Sync Boost                        : Not Active\n",
            "        SW Thermal Slowdown               : Not Active\n",
            "        Display Clock Setting             : Not Active\n",
            "    Sparse Operation Mode                 : N/A\n",
            "    FB Memory Usage\n",
            "        Total                             : 23034 MiB\n",
            "        Reserved                          : 341 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 22692 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 32768 MiB\n",
            "        Used                              : 1 MiB\n",
            "        Free                              : 32767 MiB\n",
            "    Conf Compute Protected Memory Usage\n",
            "        Total                             : 0 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 0 MiB\n",
            "    Compute Mode                          : Default\n",
            "    Utilization\n",
            "        Gpu                               : 0 %\n",
            "        Memory                            : 0 %\n",
            "        Encoder                           : 0 %\n",
            "        Decoder                           : 0 %\n",
            "        JPEG                              : 0 %\n",
            "        OFA                               : 0 %\n",
            "    Encoder Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    FBC Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    ECC Mode\n",
            "        Current                           : Enabled\n",
            "        Pending                           : Enabled\n",
            "    ECC Errors\n",
            "        Volatile\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable Parity     : 0\n",
            "            SRAM Uncorrectable SEC-DED    : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "        Aggregate\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable Parity     : 0\n",
            "            SRAM Uncorrectable SEC-DED    : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "            SRAM Threshold Exceeded       : No\n",
            "        Aggregate Uncorrectable SRAM Sources\n",
            "            SRAM L2                       : 0\n",
            "            SRAM SM                       : 0\n",
            "            SRAM Microcontroller          : 0\n",
            "            SRAM PCIE                     : 0\n",
            "            SRAM Other                    : 0\n",
            "    Retired Pages\n",
            "        Single Bit ECC                    : N/A\n",
            "        Double Bit ECC                    : N/A\n",
            "        Pending Page Blacklist            : N/A\n",
            "    Remapped Rows\n",
            "        Correctable Error                 : 0\n",
            "        Uncorrectable Error               : 0\n",
            "        Pending                           : No\n",
            "        Remapping Failure Occurred        : No\n",
            "        Bank Remap Availability Histogram\n",
            "            Max                           : 96 bank(s)\n",
            "            High                          : 0 bank(s)\n",
            "            Partial                       : 0 bank(s)\n",
            "            Low                           : 0 bank(s)\n",
            "            None                          : 0 bank(s)\n",
            "    Temperature\n",
            "        GPU Current Temp                  : 60 C\n",
            "        GPU T.Limit Temp                  : 25 C\n",
            "        GPU Shutdown T.Limit Temp         : -5 C\n",
            "        GPU Slowdown T.Limit Temp         : -2 C\n",
            "        GPU Max Operating T.Limit Temp    : 0 C\n",
            "        GPU Target Temperature            : N/A\n",
            "        Memory Current Temp               : N/A\n",
            "        Memory Max Operating T.Limit Temp : N/A\n",
            "    GPU Power Readings\n",
            "        Power Draw                        : 14.24 W\n",
            "        Current Power Limit               : 72.00 W\n",
            "        Requested Power Limit             : 72.00 W\n",
            "        Default Power Limit               : 72.00 W\n",
            "        Min Power Limit                   : 40.00 W\n",
            "        Max Power Limit                   : 72.00 W\n",
            "    GPU Memory Power Readings \n",
            "        Power Draw                        : N/A\n",
            "    Module Power Readings\n",
            "        Power Draw                        : N/A\n",
            "        Current Power Limit               : N/A\n",
            "        Requested Power Limit             : N/A\n",
            "        Default Power Limit               : N/A\n",
            "        Min Power Limit                   : N/A\n",
            "        Max Power Limit                   : N/A\n",
            "    Clocks\n",
            "        Graphics                          : 210 MHz\n",
            "        SM                                : 210 MHz\n",
            "        Memory                            : 405 MHz\n",
            "        Video                             : 765 MHz\n",
            "    Applications Clocks\n",
            "        Graphics                          : 2040 MHz\n",
            "        Memory                            : 6251 MHz\n",
            "    Default Applications Clocks\n",
            "        Graphics                          : 2040 MHz\n",
            "        Memory                            : 6251 MHz\n",
            "    Deferred Clocks\n",
            "        Memory                            : N/A\n",
            "    Max Clocks\n",
            "        Graphics                          : 2040 MHz\n",
            "        SM                                : 2040 MHz\n",
            "        Memory                            : 6251 MHz\n",
            "        Video                             : 1770 MHz\n",
            "    Max Customer Boost Clocks\n",
            "        Graphics                          : 2040 MHz\n",
            "    Clock Policy\n",
            "        Auto Boost                        : N/A\n",
            "        Auto Boost Default                : N/A\n",
            "    Voltage\n",
            "        Graphics                          : 655.000 mV\n",
            "    Fabric\n",
            "        State                             : N/A\n",
            "        Status                            : N/A\n",
            "        CliqueId                          : N/A\n",
            "        ClusterUUID                       : N/A\n",
            "        Health\n",
            "            Bandwidth                     : N/A\n",
            "    Processes                             : None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 💤 Installing nemo requirements. ( ~3 minutes...)\n",
        "\n",
        "!pip install \"numpy<2.0.0\" # (Won't be necessary for next parakeet release)\n",
        "!pip install -U nemo_toolkit['asr']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td9I_N7PVAgp",
        "outputId": "cca97aee-e13f-4306-a530-c21537857f8d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting nemo_toolkit[asr]\n",
            "  Downloading nemo_toolkit-2.3.0-py3-none-any.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.12.0 (from nemo_toolkit[asr])\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.31.1)\n",
            "Collecting numba==0.61.0 (from nemo_toolkit[asr])\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (1.26.4)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit[asr])\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting protobuf==4.24.4 (from nemo_toolkit[asr])\n",
            "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.9.0.post0)\n",
            "Collecting ruamel.yaml (from nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.18.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (4.67.1)\n",
            "Collecting wget (from nemo_toolkit[asr])\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (1.17.2)\n",
            "Collecting braceexpand (from nemo_toolkit[asr])\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Collecting g2p_en (from nemo_toolkit[asr])\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting jiwer (from nemo_toolkit[asr])\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo_toolkit[asr])\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kaldiio (from nemo_toolkit[asr])\n",
            "  Downloading kaldiio-2.18.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting lhotse>=1.26.0 (from nemo_toolkit[asr])\n",
            "  Downloading lhotse-1.31.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.11.0)\n",
            "Collecting marshmallow (from nemo_toolkit[asr])\n",
            "  Downloading marshmallow-4.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting optuna (from nemo_toolkit[asr])\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (24.2)\n",
            "Collecting pyannote.core (from nemo_toolkit[asr])\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.metrics (from nemo_toolkit[asr])\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pydub (from nemo_toolkit[asr])\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyloudnorm (from nemo_toolkit[asr])\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo_toolkit[asr])\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (1.15.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.13.1)\n",
            "Collecting sox<=1.5.0 (from nemo_toolkit[asr])\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors<1.0.0 (from nemo_toolkit[asr])\n",
            "  Downloading texterrors-0.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (3.1.1)\n",
            "Collecting fiddle (from nemo_toolkit[asr])\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit[asr])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightning<=2.4.0,>2.2.1 (from nemo_toolkit[asr])\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.15.2)\n",
            "Collecting torchmetrics>=0.11.0 (from nemo_toolkit[asr])\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (4.51.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.19.11)\n",
            "Collecting webdataset>=0.2.86 (from nemo_toolkit[asr])\n",
            "  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting bitsandbytes==0.45.3 (from nemo_toolkit[asr])\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.14.4)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (7.5.0)\n",
            "Collecting mediapy==1.1.6 (from nemo_toolkit[asr])\n",
            "  Downloading mediapy-1.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (2.2.2)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_toolkit[asr])\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit[asr]) (0.2.0)\n",
            "Collecting num2words (from nemo_toolkit[asr])\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (11.2.1)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0->nemo_toolkit[asr])\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (1.1.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]) (4.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from lhotse>=1.26.0->nemo_toolkit[asr]) (3.0.1)\n",
            "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from lhotse>=1.26.0->nemo_toolkit[asr]) (8.1.8)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse>=1.26.0->nemo_toolkit[asr])\n",
            "  Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse>=1.26.0->nemo_toolkit[asr])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from lhotse>=1.26.0->nemo_toolkit[asr]) (0.9.0)\n",
            "Collecting lilcom>=1.1.0 (from lhotse>=1.26.0->nemo_toolkit[asr])\n",
            "  Downloading lilcom-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.1.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit[asr])\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[asr]) (2024.11.6)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nemo_toolkit[asr]) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->nemo_toolkit[asr]) (1.17.1)\n",
            "Collecting pybind11 (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting plac (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from texterrors<1.0.0->nemo_toolkit[asr]) (3.1.0)\n",
            "Collecting Levenshtein (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->nemo_toolkit[asr])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit[asr]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->nemo_toolkit[asr]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->nemo_toolkit[asr]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->nemo_toolkit[asr]) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit[asr]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit[asr]) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit[asr]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit[asr]) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit[asr]) (3.11.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from fiddle->nemo_toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from fiddle->nemo_toolkit[asr]) (0.20.3)\n",
            "Collecting libcst (from fiddle->nemo_toolkit[asr])\n",
            "  Downloading libcst-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.11/dist-packages (from g2p_en->nemo_toolkit[asr]) (3.9.1)\n",
            "Collecting distance>=0.1.3 (from g2p_en->nemo_toolkit[asr])\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_toolkit[asr]) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_toolkit[asr]) (4.4.2)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer->nemo_toolkit[asr])\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting docopt>=0.6.2 (from num2words->nemo_toolkit[asr])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alembic>=1.5.0 (from optuna->nemo_toolkit[asr])\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->nemo_toolkit[asr])\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->nemo_toolkit[asr]) (2.0.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->nemo_toolkit[asr]) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft->nemo_toolkit[asr]) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft->nemo_toolkit[asr]) (1.6.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core->nemo_toolkit[asr]) (2.4.0)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr])\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pyloudnorm->nemo_toolkit[asr]) (1.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit[asr]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit[asr]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.1.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (2.11.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit[asr]) (1.3.6)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->nemo_toolkit[asr]) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[asr]) (2.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cytoolz>=0.10.1->lhotse>=1.26.0->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (3.2.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.15.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[asr]) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit[asr]) (3.0.2)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy==1.1.6->nemo_toolkit[asr])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (4.9.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.1.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapy-1.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lhotse-1.31.0-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.4/845.4 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-4.0.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_toolkit-2.3.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading lilcom-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sox, texterrors, kaldi-python-io, wget, distance, docopt, intervaltree\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=bfc9574ef066151ea50fe815a3f38a8737a5d1b19057d2b956e7891e995f6886\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/89/93/023fcdacaec4e5471e78b43992515e8500cc2505b307e2e6b7\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for texterrors: filename=texterrors-0.5.1-cp311-cp311-linux_x86_64.whl size=1077996 sha256=d4044eeefc42b01a9e27b0152af32db69a01430c3addbfe696b87a07f808dbc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/94/c8/7edaa578fc800d26e3fda18fba557a4218ab553d078ee51b46\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=8a1e4c624a9815c8e52bd4022ee5bdf9cf2c519f5e3e5f6490c56e5fd86e3804\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/86/7b/eec1bb7dc63b8aab5da6317609313873e6e75f065b65f3c29c\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=a95fcfba132ce5fe778f9e98a5fdb5204787bc9840f916f14829f26a4488e83a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=73b51218b5f6f38c80ed343a7f584f265a84c1a62c58df44fde4b70080ffb76a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/cd/9c/3ab5d666e3bcacc58900b10959edd3816cc9557c7337986322\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=4957dec89e24f9cd29f7243cee44c5876dfa0f14f0635376b4437fcc58d57dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=b4abcd82c6ad5778df5eb00bf855443f2c535844a99eb9a0f65a505a84af9e94\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built sox texterrors kaldi-python-io wget distance docopt intervaltree\n",
            "Installing collected packages: wget, pydub, plac, docopt, distance, braceexpand, webdataset, sox, sacremoses, ruamel.yaml.clib, rapidfuzz, pybind11, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, num2words, marshmallow, loguru, llvmlite, lilcom, lightning-utilities, libcst, kaldiio, kaldi-python-io, jedi, intervaltree, fsspec, cytoolz, colorlog, ruamel.yaml, pyloudnorm, pyannote.core, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, Levenshtein, jiwer, hydra-core, fiddle, alembic, texterrors, resampy, optuna, nvidia-cusolver-cu12, mediapy, g2p_en, pyannote.database, torchmetrics, pyannote.metrics, nemo_toolkit, lhotse, bitsandbytes, pytorch-lightning, lightning\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.24.4 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.24.4 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.24.4 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "yfinance 0.2.59 requires protobuf<6,>=5.29.0, but you have protobuf 4.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.27.1 alembic-1.15.2 bitsandbytes-0.45.3 braceexpand-0.1.7 colorlog-6.9.0 cytoolz-1.0.1 distance-0.1.3 docopt-0.6.2 fiddle-0.3.0 fsspec-2024.12.0 g2p_en-2.1.0 hydra-core-1.3.2 intervaltree-3.1.0 jedi-0.19.2 jiwer-3.1.0 kaldi-python-io-1.2.2 kaldiio-2.18.1 lhotse-1.31.0 libcst-1.7.0 lightning-2.4.0 lightning-utilities-0.14.3 lilcom-1.8.1 llvmlite-0.44.0 loguru-0.7.3 marshmallow-4.0.0 mediapy-1.1.6 nemo_toolkit-2.3.0 num2words-0.5.14 numba-0.61.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 optuna-4.3.0 plac-1.4.5 protobuf-4.24.4 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pybind11-2.13.6 pydub-0.25.1 pyloudnorm-0.1.1 pytorch-lightning-2.5.1.post0 rapidfuzz-3.13.0 resampy-0.4.3 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 sacremoses-0.1.1 sox-1.5.0 texterrors-0.5.1 torchmetrics-1.7.1 webdataset-0.2.111 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> RESTART SESSION\n",
        "\n",
        "Only variable to set:\n",
        "- `cur_asr_model = 'NVIDIA'`\n",
        "- colors"
      ],
      "metadata": {
        "id": "EV4sOIryrDtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import ASR model (nvidia) and define as `asr_model`\n",
        "if cur_asr_model == \"NVIDIA\":\n",
        "  import nemo.collections.asr as nemo_asr\n",
        "\n",
        "  ''' Huggingface Access required (\"HF_TOKEN\". Grant access)'''\n",
        "  # In google colab in the leftside menu bar is a icon of a key.\n",
        "  # Click on it and select Add new secret.\n",
        "  # Name it HF_TOKENand paste your new Huggingface token in there.\n",
        "  # Toggle theNotebook access` so it shows a tick.\n",
        "\n",
        "  asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v2\")\n",
        "\n",
        "  #get Sample from Nvidia:\n",
        "  # !wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav"
      ],
      "metadata": {
        "id": "YQ7UCVriVBHc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832,
          "referenced_widgets": [
            "91309d0c232c44dfa3ef8d5548e1c318",
            "1f99903d4baf4978b973f701c7d4d129",
            "b399ea107d6f4f9cab89636ac52f96a8",
            "a59e213e2c134b728ec97a3102301ee5",
            "f5c03664bf66456eb0150d311420c8e8",
            "002df19846694588bd9e739337a15cfd",
            "4dfd0a2aac124c6ea732f93bbe9e0293",
            "980cbcbc6fbc461792311a742e47072c",
            "a104e4c73a7344b9b1ff2f71cb0220b1",
            "21d272d9b1b040b8a5bfa84cb9771ca2",
            "1968a6ecebf64f4889e2f62c77d6eaf9"
          ]
        },
        "outputId": "259913b9-3526-413d-c3a4-843f72748148",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "parakeet-tdt-0.6b-v2.nemo:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91309d0c232c44dfa3ef8d5548e1c318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-05-14 17:57:49 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-05-14 17:57:49 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    use_lhotse: true\n",
            "    skip_missing_manifest_entries: true\n",
            "    input_cfg: null\n",
            "    tarred_audio_filepaths: null\n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    shuffle: true\n",
            "    num_workers: 2\n",
            "    pin_memory: true\n",
            "    max_duration: 40.0\n",
            "    min_duration: 0.1\n",
            "    text_field: answer\n",
            "    batch_duration: null\n",
            "    use_bucketing: true\n",
            "    bucket_duration_bins: null\n",
            "    bucket_batch_size: null\n",
            "    num_buckets: 30\n",
            "    bucket_buffer_size: 20000\n",
            "    shuffle_buffer_size: 10000\n",
            "    \n",
            "[NeMo W 2025-05-14 17:57:49 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    use_lhotse: true\n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    max_duration: 40.0\n",
            "    min_duration: 0.1\n",
            "    num_workers: 2\n",
            "    pin_memory: true\n",
            "    text_field: answer\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-05-14 17:57:49 nemo_logging:393] PADDING: 0\n",
            "[NeMo I 2025-05-14 17:57:54 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
            "[NeMo I 2025-05-14 17:57:54 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
            "[NeMo I 2025-05-14 17:57:54 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
            "[NeMo I 2025-05-14 17:57:57 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--parakeet-tdt-0.6b-v2/snapshots/50aec6a056e85b9f95b612df08a2bddc55b58714/parakeet-tdt-0.6b-v2.nemo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: Testing the model using the Nvidia test file\n",
        "%cd /content\n",
        "# # !wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\n",
        "\n",
        "# if cur_asr_model == 'NVIDIA':\n",
        "#   !pwd\n",
        "#   output = asr_model.transcribe(['2086-149220-0033.wav']) # 4 sec.\n",
        "# #   print(output[0].text)\n",
        "\n",
        "# =======\n",
        "# if cur_asr_model == \"NVIDIA\":\n",
        "\n",
        "#   output = asr_model.transcribe(['/content/2086-149220-0033.wav'], timestamps=True)\n",
        "#   # by default, timestamps are enabled for char, word and segment level\n",
        "#   word_timestamps = output[0].timestamp['word'] # word level timestamps for first sample\n",
        "#   segment_timestamps = output[0].timestamp['segment'] # segment level timestamps\n",
        "#   char_timestamps = output[0].timestamp['char'] # char level timestamps\n",
        "\n",
        "#   for stamp in segment_timestamps:\n",
        "#       print(f\"{stamp['start']}s - {stamp['end']}s : {stamp['segment']}\")"
      ],
      "metadata": {
        "id": "Vx4zvvcTQvji",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c83d75-eba6-467b-f4f5-6759acbfcd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='magenta'>Optional: You can download a test `/recordings/` directory with this cell.\n",
        "'''\n",
        "not required if you recorded your discord session\n",
        "'''\n",
        "# import gdown\n",
        "# import zipfile\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# # Replace with your shared link\n",
        "# shared_link = \"https://drive.google.com/file/d/1tEu6xqF9DMQ9FEcXZ4guG3uymxiVEtcZ/view?usp=sharing\"\n",
        "# shared_link = \"https://drive.google.com/file/d/1ouoroEO0tbBGXs4LNDCF9vwaM9306jZF/view?usp=sharing\"\n",
        "# # Extract the file ID from the shared link\n",
        "# file_id = shared_link.split(\"/\")[5]\n",
        "\n",
        "# # Download the file\n",
        "# output_path = \"/content/downloaded_file.zip\"\n",
        "\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
        "\n",
        "# # Unzip the file\n",
        "# with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"/content/extracted_files\")\n",
        "\n",
        "# # ==================================================\n",
        "# #@title COPY THE RECORDINGS (.wav)\n",
        "\n",
        "# recordings_dir = \"recordings\"\n",
        "\n",
        "# # Check if 'recordings' directory exists and is empty (or doesn't exist at all)\n",
        "# if not os.path.exists(recordings_dir) or not os.listdir(recordings_dir):\n",
        "#     # Create the directory if it doesn't exist\n",
        "#     os.makedirs(recordings_dir, exist_ok=True)\n",
        "\n",
        "#     # Copy the 'recordings' directory from extracted files\n",
        "#     shutil.copytree(\"/content/extracted_files/recordings\", recordings_dir, dirs_exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hphGJgzts4Rw",
        "outputId": "c4b70aa9-5bc3-4110-e300-eb4101249bb8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnot required if you recorded your discord session\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='00A115'>Step 3: Transcribe Audio Files 🔄"
      ],
      "metadata": {
        "id": "w8CoBsWABuLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import model_config\n",
        "%cd /content/tiny-tutorials/discord-transcription-bot\n",
        "import model_config\n",
        "\n",
        "if cur_asr_model == \"NVIDIA\":\n",
        "  print(\"USING NVIDIA\")\n",
        "  # model_nvidia = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\"nvidia/stt_en_conformer_ctc_large\")\n",
        "  # asr_model = model_nvidia\n",
        "  model_config.model = asr_model\n",
        "\n",
        "else:\n",
        "  # import nest_asyncio\n",
        "  # nest_asyncio.apply()\n",
        "\n",
        "  # import asyncio\n",
        "  # import whisper\n",
        "\n",
        "  # Load the model\n",
        "  # model = whisper.load_model(\"base\")\n",
        "  # print(\"Whisper model loaded successfully!\")\n",
        "\n",
        "  # Assign the model to the configuration\n",
        "  # model_config.model = whisper.load_model(\"base\")\n",
        "  model_config.model = model\n",
        "\n",
        "\n",
        "  # device = \"cpu\"\n",
        "  # model = whisperx.load_model(\"large-v2\", device, compute_type=\"float32\")\n"
      ],
      "metadata": {
        "id": "gQHM2LfFInaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b21267-c8d5-49aa-f50b-3c7b5f286b6c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tiny-tutorials/discord-transcription-bot\n",
            "USING NVIDIA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define convert nvidia_to_whisperx():\n",
        "def nvidia_to_whisperx(input_data):\n",
        "\n",
        "    result = {\"segments\": []}\n",
        "\n",
        "    # First, process segments\n",
        "    for segment in input_data.get(\"segments\", []):\n",
        "        new_segment = {\n",
        "            \"start\": segment[\"start\"],\n",
        "            \"end\": segment[\"end\"],\n",
        "            \"text\": segment[\"segment\"],\n",
        "            \"words\": []\n",
        "        }\n",
        "\n",
        "        # Find all words that belong to this segment\n",
        "        segment_start_offset = segment[\"start_offset\"]\n",
        "        segment_end_offset = segment[\"end_offset\"]\n",
        "\n",
        "        for word in input_data.get(\"words\", []):\n",
        "            # Check if word is within this segment's offset range\n",
        "            if segment_start_offset <= word[\"start_offset\"] and word[\"end_offset\"] <= segment_end_offset:\n",
        "                new_word = {\n",
        "                    \"word\": word[\"word\"],\n",
        "                    \"start\": word[\"start\"],\n",
        "                    \"end\": word[\"end\"],\n",
        "                    # \"score\": 0.8  # Adding default score since it's in target but not in source\n",
        "                }\n",
        "                new_segment[\"words\"].append(new_word)\n",
        "\n",
        "        result[\"segments\"].append(new_segment)\n",
        "\n",
        "    return result\n",
        "\n",
        "# # Example usage\n",
        "# import json\n",
        "\n",
        "# initial_data = {\n",
        "#     \"segments\": [\n",
        "#         {\n",
        "#             \"segment\": \"Hello, this is the second account.\",\n",
        "#             \"start_offset\": 2,\n",
        "#             \"end_offset\": 32,\n",
        "#             \"start\": 0.16,\n",
        "#             \"end\": 2.56\n",
        "#         },\n",
        "#         # ... other segments ...\n",
        "#     ],\n",
        "#     \"words\": [\n",
        "#         {\n",
        "#             \"word\": \"Hello,\",\n",
        "#             \"start_offset\": 2,\n",
        "#             \"end_offset\": 8,\n",
        "#             \"start\": 0.16,\n",
        "#             \"end\": 0.64\n",
        "#         },\n",
        "#         # ... other words ...\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "# converted = nvidia_to_whisperx(initial_data)\n",
        "# print(json.dumps(converted, indent=2))"
      ],
      "metadata": {
        "id": "7gN6FxTv_NXR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='00A115'>✍ transcribe_all_recordings\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import model_config\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "\n",
        "CYAN = \"\\033[96m\"\n",
        "RED = '\\033[31m'\n",
        "RESET = \"\\033[0m\"\n",
        "\n",
        "\n",
        "def transcribe_with_nvidia_parakeet(audio_path):\n",
        "\n",
        "      # Construct the cleaned file path\n",
        "      cleaned_path = audio_path.replace(\".wav\", \"_cleaned.wav\")\n",
        "\n",
        "      # Run ffmpeg to re-encode the file to single-channel, 16kHz\n",
        "      subprocess.run([\n",
        "          \"ffmpeg\", \"-y\",          # Overwrite without prompting\n",
        "          \"-i\", audio_path,        # Input file\n",
        "          \"-ac\", \"1\",              # Force mono audio\n",
        "          \"-ar\", \"16000\",          # Force 16kHz sample rate\n",
        "          cleaned_path\n",
        "      ], check=True)\n",
        "\n",
        "      # Verify that the cleaned file has audio data using soundfile\n",
        "      data, sr = sf.read(cleaned_path)\n",
        "      if len(data) == 0:\n",
        "          raise ValueError(f\"Converted audio file {cleaned_path} has no data!\")\n",
        "      else:\n",
        "          print(f\"Converted file has {len(data)} samples at {sr} Hz.\")\n",
        "\n",
        "      # Use the cleaned file for transcription\n",
        "      audio_path = cleaned_path\n",
        "      print(f\"{CYAN}{audio_path}{RESET}\")\n",
        "      output = asr_model.transcribe([audio_path], timestamps=True)\n",
        "\n",
        "      for stamp in output[0].timestamp['segment']:\n",
        "          print(f\"{CYAN}{stamp['start']}s - {stamp['end']}s : {stamp['segment']}{RESET}\")\n",
        "\n",
        "      # transcription = asr_model.transcribe(['/content/2086-149220-0033.wav'], timestamps=True)\n",
        "      # word_timestamps = output[0].timestamp['word'] # word level timestamps for first sample\n",
        "      # segment_timestamps = output[0].timestamp['segment'] # segment level timestamps\n",
        "      # char_timestamps = output[0].timestamp['char'] # char level timestamps\n",
        "\n",
        "      transcription_text = nvidia_to_whisperx(\n",
        "          {\n",
        "          \"segments\": output[0].timestamp['segment'],\n",
        "          \"words\" :output[0].timestamp['word']\n",
        "          }\n",
        "      )\n",
        "      return transcription_text\n",
        "\n",
        "\n",
        "def transcribe_with_nvidia_whisperx(audio_path):\n",
        "    audio = whisperx.load_audio(audio_path)\n",
        "    transcription = model_config.model.transcribe(audio)\n",
        "    transcription = whisperx.align(transcription[\"segments\"],\n",
        "                                    model_a,\n",
        "                                    metadata_model_a,\n",
        "                                    audio,\n",
        "                                    device,\n",
        "                                    return_char_alignments=False)\n",
        "    transcription_text = transcription if transcription.get('segments', None) else transcription[\"text\"]\n",
        "\n",
        "    return transcription_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transcribe_all_recordings(skip_existing=True):\n",
        "    \"\"\"\n",
        "    Transcribes all audio recordings in the 'recordings' directory using the Whisper model.\n",
        "    Saves transcriptions as text files and updates metadata.json for each user.\n",
        "    If skip_existing is True, it will not re-transcribe already existing transcription files.\n",
        "    \"\"\"\n",
        "    model_config.model = model_config.model  # Ensure model is set (redundant here if already set)\n",
        "\n",
        "    recordings_dir = \"recordings\"\n",
        "    if not os.path.exists(recordings_dir):\n",
        "        print(\"Error: The 'recordings' directory does not exist.\")\n",
        "        return\n",
        "\n",
        "    for user_id in os.listdir(recordings_dir):\n",
        "        user_dir = os.path.join(recordings_dir, user_id)\n",
        "        if not os.path.isdir(user_dir):\n",
        "            continue\n",
        "\n",
        "        metadata_path = os.path.join(user_dir, \"metadata.json\")\n",
        "        if not os.path.exists(metadata_path):\n",
        "            print(f\"Warning: No metadata.json found for user {user_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(metadata_path, \"r\") as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "        for recording in metadata.get(\"recordings\", []):\n",
        "            audio_file = recording.get(\"audio_file\")\n",
        "            if not audio_file:\n",
        "                print(f\"Warning: No audio_file specified in metadata for user {user_id}. Skipping entry.\")\n",
        "                continue\n",
        "\n",
        "            audio_path = os.path.join(user_dir, audio_file)\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(f\"Warning: Audio file {audio_path} not found. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            transcription_file = f\"{os.path.splitext(audio_file)[0]}_transcription.json\"\n",
        "            transcription_path = os.path.join(user_dir, transcription_file)\n",
        "\n",
        "            if skip_existing and os.path.exists(transcription_path):\n",
        "                print(f\"Skipping existing transcription for {audio_file}.\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "\n",
        "                if cur_asr_model == \"WHISPERX\":\n",
        "                    transcription_text = transcribe_with_nvidia_parakeet(\n",
        "                       audio_path=audio_path\n",
        "                    )\n",
        "                elif cur_asr_model == \"NVIDIA\":\n",
        "                    transcription_text = transcribe_with_nvidia_parakeet(\n",
        "                        audio_path=audio_path\n",
        "                    )\n",
        "                else:\n",
        "                  raise ValueError(f\"Unknown ASR model: {cur_asr_model}\")\n",
        "\n",
        "                end_time = time.time()\n",
        "                duration = end_time - start_time\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error: Failed to transcribe {audio_path}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            with open(transcription_path, \"w\") as f:\n",
        "                f.write(json.dumps(transcription_text, indent=4, ensure_ascii=False))\n",
        "\n",
        "            recording[\"transcription_file\"] = transcription_file\n",
        "            recording[\"transcription_time_seconds\"] = round(duration, 2)\n",
        "            print(f\"{RED}Transcribed {audio_file} in {duration:.2f} seconds.{RESET}\")\n",
        "\n",
        "        with open(metadata_path, \"w\") as f:\n",
        "            json.dump(metadata, f, indent=4)\n",
        "\n",
        "        print(f\"Success: Transcriptions completed for user {user_id}\")\n",
        "\n",
        "# Example usage:\n",
        "%cd /content\n",
        "# transcribe_all_recordings(skip_existing=True)  # Skips existing transcriptions\n",
        "transcribe_all_recordings(skip_existing=False)  # Re-transcribes all files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMiHDReXXH04",
        "outputId": "bc8b7b5d-8af5-4ae6-b71a-5b71e0831985",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Converted file has 10097276 samples at 16000 Hz.\n",
            "\u001b[96mrecordings/runfishrun/session_20250514_17M51_cleaned.wav\u001b[0m\n",
            "[NeMo I 2025-05-14 17:57:58 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n",
            "[NeMo I 2025-05-14 17:57:58 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-05-14 17:57:58 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\n",
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m4.72s - 7.36s : Yeah, I don't know what's your stream on here.\u001b[0m\n",
            "\u001b[96m20.080000000000002s - 22.240000000000002s : Yeah, so how is that going?\u001b[0m\n",
            "\u001b[96m70.88s - 73.92s : Yeah, I just get this bot done.\u001b[0m\n",
            "\u001b[96m74.88s - 85.68s : I also think about how to add like text to the video, like to make us to make it a mask or something like that to put it over there.\u001b[0m\n",
            "\u001b[96m89.04s - 91.92s : This is gonna be difficult, I don't know.\u001b[0m\n",
            "\u001b[96m114.56s - 138.32s : Okay, but you can do like how long can the videos be on Canvas so Canvas is like really not just for ports, but also for long videos or what?\u001b[0m\n",
            "\u001b[96m150.72s - 156.8s : Okay, yeah, this is it's so much work.\u001b[0m\n",
            "\u001b[96m173.36s - 173.68s : Yeah.\u001b[0m\n",
            "\u001b[96m189.28s - 189.6s : Yeah.\u001b[0m\n",
            "\u001b[96m206.72s - 207.84s : Up to one terabyte.\u001b[0m\n",
            "\u001b[96m207.92000000000002s - 209.52s : So that's like uh four.\u001b[0m\n",
            "\u001b[96m210.08s - 210.64000000000001s : Yeah, okay.\u001b[0m\n",
            "\u001b[96m212.08s - 230.8s : I mean, that's yeah, uh, yeah, but not too long.\u001b[0m\n",
            "\u001b[96m231.12s - 241.52s : I mean, if you have a normal HD movie like 1080, uh, two hours is about is at least four gigabytes.\u001b[0m\n",
            "\u001b[96m264.16s - 269.68s : Yeah, yeah, that's that's yeah, it's really good.\u001b[0m\n",
            "\u001b[96m269.92s - 277.6s : Uh, I'm really afraid that this is like too complicated with the tools that I'm using.\u001b[0m\n",
            "\u001b[96m299.36s - 302.72s : Yeah, I know these kinds of situations.\u001b[0m\n",
            "\u001b[96m302.88s - 308.56s : Uh, so in that case, but but you know exactly you cannot trust what it says.\u001b[0m\n",
            "\u001b[96m308.88s - 327.2s : So, in this case, you can kind of go to perplexity or yeah, normally I just go to perplexity and then maybe to Google Gemini because Gemini can also have like this search function, and they just sometimes one model is just wrong.\u001b[0m\n",
            "\u001b[96m327.6s - 336.08s : Sometimes one model is just particularly bad at something, then I just switch to another, and and and most and all the others they know it.\u001b[0m\n",
            "\u001b[96m393.2s - 404.56s : Yeah, I mean, we can just run this bot non-stop and make like how is how's this thing called uh URL hook or something?\u001b[0m\n",
            "\u001b[96m404.88s - 417.6s : And then it and yeah, we can just like you know it's so yeah, it's it's not so expensive, and if this yeah, it's it's a super small model.\u001b[0m\n",
            "\u001b[96m417.84000000000003s - 423.68s : It's we could really to run this for the whole month always be accessible.\u001b[0m\n",
            "\u001b[96m423.92s - 427.68s : I don't know, maybe this just like 30-40 US dollar.\u001b[0m\n",
            "\u001b[96m459.68s - 473.28000000000003s : Yeah, so the friends from Holland, they really they don't this guy, I mean the coach basically, he uh he doesn't like Notion, but I don't know why.\u001b[0m\n",
            "\u001b[96m473.52s - 490.96000000000004s : Maybe he doesn't like it because uh he switched too many times between these tools and then he never he never got to Notion, you know, and now he's like this everybody tells him, Hey, Notion is so good, and he's just oh, I'm done with switching, and I think it's like that.\u001b[0m\n",
            "\u001b[96m492.16s - 495.68s : And but but he is recommending like click up.\u001b[0m\n",
            "\u001b[96m496.0s - 497.2s : I don't know if you notice.\u001b[0m\n",
            "\u001b[96m500.32s - 506.24s : Oh okay, yeah, yeah.\u001b[0m\n",
            "\u001b[96m517.6800000000001s - 531.6800000000001s : Yeah, um, I don't know if if click up is is growing faster because they have like really cool features, but I never tried it, so I cannot.\u001b[0m\n",
            "\u001b[96m531.84s - 536.08s : I think it's also it's paid mostly, so that's a problem.\u001b[0m\n",
            "\u001b[96m538.24s - 545.2s : It has like this calendar calendar and timeline and planning features, which are really, really good.\u001b[0m\n",
            "\u001b[96m561.36s - 570.32s : Oh no, yeah, yeah, okay, we got it on tape, but it's so normal, man.\u001b[0m\n",
            "\u001b[96m570.64s - 574.24s : It's it's just this happens to me all the time, too.\u001b[0m\n",
            "\u001b[96m574.48s - 578.0s : Like, what is this AI output is wrong?\u001b[0m\n",
            "\u001b[96m578.32s - 586.0s : And then 15 minutes later, damn, why didn't I follow it?\u001b[0m\n",
            "\u001b[96m586.24s - 587.52s : It would write again.\u001b[0m\n",
            "\u001b[96m590.32s - 590.5600000000001s : Yeah.\u001b[0m\n",
            "\u001b[96m594.0s - 594.32s : Yeah.\u001b[0m\n",
            "\u001b[96m605.6s - 605.76s : Yeah.\u001b[0m\n",
            "\u001b[96m608.0s - 608.24s : Okay.\u001b[0m\n",
            "\u001b[96m618.96s - 630.4s : It's the analog work stop if it's got the extra transcriber in principle.\u001b[0m\n",
            "\u001b[31mTranscribed session_20250514_17M51.wav in 10.32 seconds.\u001b[0m\n",
            "Success: Transcriptions completed for user runfishrun\n",
            "Converted file has 9735036 samples at 16000 Hz.\n",
            "\u001b[96mrecordings/Unknown/session_20250514_17M51_cleaned.wav\u001b[0m\n",
            "[NeMo I 2025-05-14 17:58:08 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n",
            "[NeMo I 2025-05-14 17:58:08 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-05-14 17:58:08 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\n",
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m0.08s - 1.04s : No, it's okay.\u001b[0m\n",
            "\u001b[96m1.68s - 9.68s : Just working on the video, you know, trying to dissolve and put some sliders in a better position.\u001b[0m\n",
            "\u001b[96m15.68s - 20.400000000000002s : I'm currently helping myself with ChatGPT due to it's new for me.\u001b[0m\n",
            "\u001b[96m21.44s - 25.12s : But I'm seriously thinking to change a different program after this.\u001b[0m\n",
            "\u001b[96m25.36s - 29.36s : Like that's the one and only project I'm doing with Canvas.\u001b[0m\n",
            "\u001b[96m30.88s - 47.04s : It's like because when you have slides and then you have you make different slides in between those slides, there's a millisecond of a screen flicker which quickly flashes and like it's really making a weird behavior.\u001b[0m\n",
            "\u001b[96m47.36s - 54.32s : So it's asking, it's telling me to dissolve in between with a little plus, but there is no plus.\u001b[0m\n",
            "\u001b[96m54.480000000000004s - 58.96s : Like GPT tells me clearly there's a little plus, but that's what it is.\u001b[0m\n",
            "\u001b[96m59.120000000000005s - 59.6s : Like, yeah.\u001b[0m\n",
            "\u001b[96m60.160000000000004s - 61.76s : What are you working on?\u001b[0m\n",
            "\u001b[96m70.96000000000001s - 71.52s : Yes.\u001b[0m\n",
            "\u001b[96m78.88s - 79.92s : Absolute.\u001b[0m\n",
            "\u001b[96m84.96000000000001s - 88.96000000000001s : Canvas is usually very, very good with text over things.\u001b[0m\n",
            "\u001b[96m89.60000000000001s - 94.32000000000001s : Like in the end, you can always put it in Canvas and you get a free month all the time.\u001b[0m\n",
            "\u001b[96m94.64s - 103.12s : So once you use a free month Google, one account, you get a free month and the next month you take another account and have another free month.\u001b[0m\n",
            "\u001b[96m103.36s - 104.0s : That's how I do it.\u001b[0m\n",
            "\u001b[96m104.08s - 105.84s : This is my third account.\u001b[0m\n",
            "\u001b[96m112.88s - 123.60000000000001s : I think with the pro version, you'd be good in any length, like because you get the free pro version literally for one month for free with this little life hack.\u001b[0m\n",
            "\u001b[96m125.68s - 139.6s : But I definitely have to ask what's the microsign on size of a video on the canvas.\u001b[0m\n",
            "\u001b[96m150.4s - 151.44s : That's for real.\u001b[0m\n",
            "\u001b[96m151.76s - 164.72s : But I'm assuming I think like my friend, we need someone that shows us sometimes little video editing, maybe with a woman with some social media skills.\u001b[0m\n",
            "\u001b[96m165.52s - 166.96s : I mean, we have social media.\u001b[0m\n",
            "\u001b[96m167.12s - 171.20000000000002s : It's just like some graphical that things go faster.\u001b[0m\n",
            "\u001b[96m171.44s - 172.96s : It's not that we're not able to do it.\u001b[0m\n",
            "\u001b[96m173.12s - 179.28s : I'm just feeling like sometimes I use too much time on my social media editing and trying.\u001b[0m\n",
            "\u001b[96m180.56s - 182.56s : But it's not like I don't want to learn it.\u001b[0m\n",
            "\u001b[96m182.8s - 184.0s : I really like it.\u001b[0m\n",
            "\u001b[96m184.32s - 194.8s : But it's it says three to pro five gigabytes per video or up to one terabyte.\u001b[0m\n",
            "\u001b[96m203.92000000000002s - 210.96s : The newer kind of super pro videos, yeah, for like the high-end HD videos.\u001b[0m\n",
            "\u001b[96m211.12s - 217.84s : It's probably not the one tool you want, but anything that has like I think like HD should be working.\u001b[0m\n",
            "\u001b[96m229.20000000000002s - 229.44s : Yeah.\u001b[0m\n",
            "\u001b[96m234.16s - 235.52s : Okay, that's a lot.\u001b[0m\n",
            "\u001b[96m236.16s - 241.36s : But so you cannot make literally one hour to two hour videos on here, edit it and everything.\u001b[0m\n",
            "\u001b[96m241.6s - 249.28s : That's definitely enough because Canvas is mostly used for like short videos or like titles and overlays on it.\u001b[0m\n",
            "\u001b[96m249.36s - 255.20000000000002s : So once you're done, it has really cool features for like the text and elements.\u001b[0m\n",
            "\u001b[96m257.36s - 258.8s : Simple and free.\u001b[0m\n",
            "\u001b[96m270.32s - 273.84000000000003s : That could be so in the end we just send it on Canva.\u001b[0m\n",
            "\u001b[96m274.16s - 277.6s : And ChatGPT knows Canva very well for whatever reason.\u001b[0m\n",
            "\u001b[96m277.84000000000003s - 282.08s : He's literally copy-pasting everything ready, telling you where to click.\u001b[0m\n",
            "\u001b[96m282.56s - 290.32s : But right now I don't like ChatGPT Canva because it tells me there's a little plus here, which I can make it dissolve, but it's not happening.\u001b[0m\n",
            "\u001b[96m329.12s - 331.76s : Yeah, I don't know why it keeps looping.\u001b[0m\n",
            "\u001b[96m332.24s - 332.64s : You're right.\u001b[0m\n",
            "\u001b[96m332.8s - 337.28000000000003s : I'm gonna literally instantly ask Perplexity about help.\u001b[0m\n",
            "\u001b[96m337.76s - 342.64s : Hey, are you a pro at video editing in Canvas?\u001b[0m\n",
            "\u001b[96m343.52s - 350.0s : I need to slides.\u001b[0m\n",
            "\u001b[96m350.32s - 608.4s : Yeah, and I'm like very excited about our future bot which takes a note because we have a lot of meetings and a lot of people have AI bots right now which make them even more meetings and so it will it will lead to that people need to take a lot of notes due to they have to be multiple places at the same time and this but will make life easy and I'm really looking forward to just also have fun with it like recording people in the call and instantly catching them for fake lies fake news just put them on the table yeah exactly in NHL yes so it sends the transcript to NAN and from there on we're gonna transcribe it in an agent make a little task and send it through whatever through Notion back or whatever the client likes WhatsApp or so you you can get your little list or your little output in the analyzing tool yes for sure that like notion I read now about it today I didn't know it's a cool tool I need to try it out yeah I'm closing yeah I know I think I used it one time heard about it but I can't really remember I haven't really I heard more about notion and let's see from implementation and now this is more the tool I would choose let's see I mean meanwhile I realized that ChatGPT wasn't really a problem it was maybe still me I couldn't find it in LittleBetween so yeah there is a little plus button right a transition yeah it is what it is we're learning we're learning what happened here and why the fuck is it different cuts now um ah this where is this came from whatever I'm learning so we're gonna put me in\u001b[0m\n",
            "\u001b[31mTranscribed session_20250514_17M51.wav in 9.30 seconds.\u001b[0m\n",
            "Success: Transcriptions completed for user Unknown\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CPU:\n",
        "    - 204 sec recording: 147 sec to transcribe\n",
        "    - 60 sec          : 32 sec to transcribe"
      ],
      "metadata": {
        "id": "3yBrR9ZLvOvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding speaker identification to nvidiaparakeet\n",
        "- https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2/discussions/16"
      ],
      "metadata": {
        "id": "oBdLrPBR1ouw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define refine segment splits\n",
        "\n",
        "def refine_split_segments(transcript_data, time_threshold=5.0):\n",
        "    \"\"\"\n",
        "    Splits transcript segments when there's a gap larger than the threshold between consecutive words.\n",
        "\n",
        "    Args:\n",
        "        transcript_data (list or dict): Either a list of transcript segments or a single segment dict\n",
        "        time_threshold (float): Maximum allowed time gap between words (in seconds)\n",
        "\n",
        "    Returns:\n",
        "        list: A list of segment dictionaries in the same format as the input\n",
        "    \"\"\"\n",
        "    # Handle input that's already a list or convert single dict to list\n",
        "    segments_list = transcript_data if isinstance(transcript_data, list) else [transcript_data]\n",
        "    result = []\n",
        "\n",
        "    # Process each segment\n",
        "    for segment in segments_list:\n",
        "        # Handle edge cases\n",
        "        if not segment or 'words' not in segment or len(segment.get('words', [])) <= 1:\n",
        "            result.append(segment)\n",
        "            continue\n",
        "\n",
        "        words = segment['words']\n",
        "\n",
        "        # Find breakpoints where time gap exceeds threshold\n",
        "        breakpoints = [i for i in range(1, len(words))\n",
        "                      if words[i]['start'] - words[i-1]['end'] > time_threshold]\n",
        "\n",
        "        # If no breakpoints found, keep original segment\n",
        "        if not breakpoints:\n",
        "            result.append(segment)\n",
        "            continue\n",
        "\n",
        "        # Create segments based on breakpoints\n",
        "        breakpoints = [0] + breakpoints + [len(words)]  # Add start and end indices\n",
        "\n",
        "        # Create all segments in one loop\n",
        "        for i in range(len(breakpoints) - 1):\n",
        "            start_idx = breakpoints[i]\n",
        "            end_idx = breakpoints[i+1]\n",
        "            segment_words = words[start_idx:end_idx]\n",
        "\n",
        "            result.append({\n",
        "                \"start\": segment_words[0]['start'],\n",
        "                \"end\": segment_words[-1]['end'],\n",
        "                \"text\": \" \".join(w['word'] for w in segment_words),\n",
        "                \"words\": segment_words\n",
        "            })\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# example_data = [{\n",
        "#     \"start\": 103.68,\n",
        "#     \"end\": 166.88,\n",
        "#     \"text\": \"Let's see, I heard the echo that was pretty hard.\",\n",
        "#     \"words\": [\n",
        "#         {\"word\": \"Let's\", \"start\": 103.68, \"end\": 104.32000000000001},\n",
        "#         {\"word\": \"see\", \"start\": 104.32000000000001, \"end\": 104.56},\n",
        "#         {\"word\": \"Yeah,\", \"start\": 153.12, \"end\": 153.44},\n",
        "#         {\"word\": \"I\", \"start\": 153.76, \"end\": 154.0},\n",
        "#         {\"word\": \"heard\", \"start\": 154.0, \"end\": 154.48},\n",
        "#         {\"word\": \"the\", \"start\": 154.48, \"end\": 154.72},\n",
        "#         {\"word\": \"echo\", \"start\": 154.72, \"end\": 155.28},\n",
        "#         {\"word\": \"that\", \"start\": 155.52, \"end\": 155.76},\n",
        "#         {\"word\": \"was\", \"start\": 155.76, \"end\": 156.0},\n",
        "#         {\"word\": \"pretty\", \"start\": 156.0, \"end\": 156.48},\n",
        "#         {\"word\": \"hard.\", \"start\": 166.48, \"end\": 166.88}\n",
        "#     ]\n",
        "# }]\n",
        "\n",
        "# # Split with a threshold of 5 seconds\n",
        "# results = refine_split_segments(example_data, 5.0)\n",
        "\n",
        "# # Print the results\n",
        "# print(f\"Found {len(results)} segments:\")\n",
        "# for i, segment in enumerate(results):\n",
        "#     print(f\"\\nSegment {i+1}:\")\n",
        "#     print(f\"  Start: {segment['start']}\")\n",
        "#     print(f\"  End: {segment['end']}\")\n",
        "#     print(f\"  Text: {segment['text']}\")\n",
        "#     print(f\"  Words: {len(segment['words'])}\")"
      ],
      "metadata": {
        "id": "ROEDqku-5Kol",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title calculate_time_offset & adjust_transcription_times\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Define color codes for output (optional, assuming they’re defined elsewhere if needed)\n",
        "GREEN = '\\033[92m'\n",
        "RESET = '\\033[0m'\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"Loads a JSON file and returns its contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_time_offset(recording, reference_time):\n",
        "    \"\"\"\n",
        "    Calculates time difference between user start time and the reference time in seconds.\n",
        "\n",
        "    Args:\n",
        "        recording (dict): Recording metadata with user_recording_start_time.\n",
        "        reference_time (datetime): The unified reference time (earliest session_start_time).\n",
        "\n",
        "    Returns:\n",
        "        float: Time offset in seconds, or None if parsing fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        user_dt = datetime.strptime(recording[\"user_recording_start_time\"], \"%Y-%m-%d %H:%M:%S\")\n",
        "        offset = (user_dt - reference_time).total_seconds()\n",
        "        print(f\"{GREEN}total_seconds offset for {recording['audio_file']}: {offset}{RESET}\")\n",
        "        return offset\n",
        "    except ValueError as e:\n",
        "        print(f\"Time parsing failed for {recording['audio_file']}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_transcription_path(user_dir, audio_file):\n",
        "    \"\"\"Constructs and validates the transcription file path.\"\"\"\n",
        "    audio_base = os.path.splitext(audio_file)[0]\n",
        "    trans_file = f\"{audio_base}_transcription.json\"\n",
        "    trans_path = os.path.join(user_dir, trans_file)\n",
        "    if not os.path.exists(trans_path):\n",
        "        print(f\"Missing transcription: {trans_path}\")\n",
        "        return None\n",
        "    return trans_path\n",
        "\n",
        "def adjust_timestamps(transcription, time_offset):\n",
        "    \"\"\"Adjusts all start and end times in the transcription by the offset.\"\"\"\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        segment[\"start\"] += time_offset\n",
        "        segment[\"end\"] += time_offset\n",
        "        for word in segment[\"words\"]:\n",
        "            word[\"start\"] = word.get(\"start\", 0) + time_offset\n",
        "            word[\"end\"] = word.get(\"end\", 0) + time_offset\n",
        "\n",
        "def save_adjusted_transcription(trans_path, transcription):\n",
        "    \"\"\"Saves the adjusted transcription to a new file.\"\"\"\n",
        "    new_trans_path = trans_path.replace(\".json\", \"_adjusted.json\")\n",
        "    with open(new_trans_path, 'w') as f:\n",
        "        json.dump(transcription, f, indent=4)\n",
        "    print(f\"Saved adjusted transcription to {new_trans_path}\")\n",
        "\n",
        "def adjust_transcription_times(metadata_path, reference_time):\n",
        "    \"\"\"\n",
        "    Shifts timing in transcription files to align with the earliest session start time.\n",
        "\n",
        "    Args:\n",
        "        metadata_path (str): Path to metadata JSON file (e.g., 'recordings/<user_id>/metadata.json').\n",
        "        reference_time (datetime): The earliest session_start_time across all sessions.\n",
        "    \"\"\"\n",
        "    metadata = load_json_file(metadata_path)\n",
        "    if not metadata:\n",
        "        return\n",
        "\n",
        "    user_dir = os.path.dirname(metadata_path)\n",
        "    for recording in metadata[\"recordings\"]:\n",
        "        time_offset = calculate_time_offset(recording, reference_time)\n",
        "        if time_offset is None:\n",
        "            continue\n",
        "\n",
        "        trans_path = get_transcription_path(user_dir, recording[\"audio_file\"])\n",
        "        if not trans_path:\n",
        "            continue\n",
        "\n",
        "        transcription = load_json_file(trans_path)\n",
        "\n",
        "        if not transcription:\n",
        "            continue\n",
        "\n",
        "        transcription[\"segments\"] = refine_split_segments(\n",
        "            transcription[\"segments\"],\n",
        "            time_threshold=5.0\n",
        "        )\n",
        "\n",
        "        adjust_timestamps(transcription, time_offset)\n",
        "        save_adjusted_transcription(trans_path, transcription)\n",
        "\n",
        "# Process all user directories\n",
        "base_dir = \"/content/tiny-tutorials/discord-transcription-bot/recordings\"\n",
        "base_dir = \"/content/recordings\"\n",
        "\n",
        "user_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "\n",
        "# Step 1: Find the earliest session_start_time (T0)\n",
        "session_start_times = []\n",
        "for user_dir in user_dirs:\n",
        "    metadata_path = os.path.join(base_dir, user_dir, \"metadata.json\")\n",
        "    metadata = load_json_file(metadata_path)\n",
        "    if metadata:\n",
        "        for recording in metadata[\"recordings\"]:\n",
        "            session_start_times.append(recording[\"session_start_time\"])\n",
        "\n",
        "if not session_start_times:\n",
        "    print(\"No session start times found. Cannot proceed with adjustments.\")\n",
        "else:\n",
        "    # Convert to datetime objects and find the minimum\n",
        "    session_start_datetimes = [datetime.strptime(st, \"%Y-%m-%d %H:%M:%S\") for st in session_start_times]\n",
        "    T0 = min(session_start_datetimes)\n",
        "    start_time_str = str(T0)\n",
        "    print(f\"Earliest session start time (T0): {T0}\")\n",
        "\n",
        "    # Step 2: Adjust transcriptions using T0 as the unified reference\n",
        "    for user_dir in user_dirs:\n",
        "        metadata_path = os.path.join(base_dir, user_dir, \"metadata.json\")\n",
        "        adjust_transcription_times(metadata_path, T0)"
      ],
      "metadata": {
        "id": "H8YTa0gTrOY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58f4aad-5b7d-4048-e5a7-d4a0799f7229",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest session start time (T0): 2025-05-14 17:46:17\n",
            "\u001b[92mtotal_seconds offset for session_20250514_17M51.wav: 2.0\u001b[0m\n",
            "Saved adjusted transcription to /content/recordings/runfishrun/session_20250514_17M51_transcription_adjusted.json\n",
            "\u001b[92mtotal_seconds offset for session_20250514_17M51.wav: 10.0\u001b[0m\n",
            "Saved adjusted transcription to /content/recordings/Unknown/session_20250514_17M51_transcription_adjusted.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title create_unified_transcription_object\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Custom function to handle datetime serialization\n",
        "def custom_serializer(obj):\n",
        "    if isinstance(obj, datetime):\n",
        "        return obj.isoformat()  # Convert datetime to an ISO 8601 string\n",
        "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
        "\n",
        "def create_unified_transcription_object( start_time_str, recordings_dir=\"recordings\"):\n",
        "    \"\"\"\n",
        "    Creates a unified JSON-like object from transcription files in the recordings directory.\n",
        "    Each segment includes the username and is sorted by absolute start time.\n",
        "\n",
        "    Args:\n",
        "        recordings_dir (str): Path to the 'recordings' directory.\n",
        "\n",
        "    Returns:\n",
        "        list: Sorted list of segment dictionaries with username, start, end, and text.\n",
        "    \"\"\"\n",
        "    all_segments = []\n",
        "\n",
        "    # Iterate over each user directory in 'recordings'\n",
        "    for user_dir in os.listdir(recordings_dir):\n",
        "        user_path = os.path.join(recordings_dir, user_dir)\n",
        "        if not os.path.isdir(user_path):\n",
        "            continue\n",
        "\n",
        "        # Load metadata.json\n",
        "        metadata_path = os.path.join(user_path, \"metadata.json\")\n",
        "        if not os.path.exists(metadata_path):\n",
        "            print(f\"Warning: metadata.json not found in {user_path}\")\n",
        "            continue\n",
        "\n",
        "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "        # Process each recording in metadata\n",
        "        for recording in metadata.get(\"recordings\", []):\n",
        "            username = recording.get(\"username\")\n",
        "            if not username:\n",
        "                print(f\"Warning: No username found in recording {recording}\")\n",
        "                continue\n",
        "\n",
        "            if not start_time_str:\n",
        "                print(f\"Warning: No user_recording_start_time in {recording}\")\n",
        "                continue\n",
        "            try:\n",
        "                recording_start = datetime.strptime(start_time_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing time {start_time_str}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Derive the adjusted transcription file name\n",
        "            transcription_file = recording.get(\"transcription_file\")\n",
        "            if not transcription_file:\n",
        "                print(f\"Warning: No transcription_file in {recording}\")\n",
        "                continue\n",
        "            # Replace '_transcription.json' with '_transcription_adjusted.json'\n",
        "            adjusted_file = transcription_file.replace(\"_transcription.json\", \"_transcription_adjusted.json\")\n",
        "            adjusted_path = os.path.join(user_path, adjusted_file)\n",
        "\n",
        "            # Load the transcription file\n",
        "            if not os.path.exists(adjusted_path):\n",
        "                print(f\"Warning: {adjusted_file} not found in {user_path}\")\n",
        "                continue\n",
        "\n",
        "            with open(adjusted_path, 'r', encoding='utf-8') as f:\n",
        "                transcription = json.load(f)\n",
        "\n",
        "            # Process each segment\n",
        "            for segment in transcription.get(\"segments\", []):\n",
        "                rel_start = segment.get(\"start\")\n",
        "                rel_end = segment.get(\"end\")\n",
        "                text = segment.get(\"text\")\n",
        "\n",
        "                if rel_start is None or rel_end is None or not text:\n",
        "                    print(f\"Warning: Incomplete segment in {adjusted_file}: {segment}\")\n",
        "                    continue\n",
        "\n",
        "                # Calculate absolute times\n",
        "                abs_start = recording_start + timedelta(seconds=rel_start)\n",
        "                abs_end = recording_start + timedelta(seconds=rel_end)\n",
        "\n",
        "                # Create segment dictionary\n",
        "                segment_dict = {\n",
        "                    \"username\": username,\n",
        "                    \"start\": abs_start,  # datetime object\n",
        "                    \"end\": abs_end,      # datetime object\n",
        "                    \"text\": text\n",
        "                }\n",
        "                all_segments.append(segment_dict)\n",
        "\n",
        "    # Sort all segments by absolute start time\n",
        "    all_segments.sort(key=lambda x: x[\"start\"])\n",
        "\n",
        "    return all_segments\n",
        "\n",
        "\n",
        "unified_object = create_unified_transcription_object(start_time_str)\n",
        "unified_obj_path =      base_dir + '/unified_object.json'\n",
        "final_transcript_path = base_dir + '/transcript.txt'\n",
        "# Save JSON with datetime converted to string\n",
        "with open(unified_obj_path, 'w') as f:\n",
        "    json.dump(unified_object, f, indent=2, default=custom_serializer)"
      ],
      "metadata": {
        "id": "cDWvraGhrL1V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='00A115'> Result"
      ],
      "metadata": {
        "id": "G9DqY6Dl1YFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='00A115'> json_to_text_transcript ()\n",
        "from datetime import datetime\n",
        "\n",
        "def json_to_text_transcript(data, WebVTT=False):\n",
        "    # List to store groups of consecutive entries\n",
        "    groups = []\n",
        "    current_group = None\n",
        "\n",
        "    # Step 1: Group consecutive entries by speaker\n",
        "    for entry in data:\n",
        "        if current_group is None or entry['username'] == current_group['speaker']:\n",
        "            # If no current group exists, start a new one\n",
        "            if current_group is None:\n",
        "                current_group = {\n",
        "                    'speaker': entry['username'],\n",
        "                    'start_time': entry['start'],\n",
        "                    'end_time': entry['end'],\n",
        "                    'texts': [entry['text'].strip()]\n",
        "                }\n",
        "            # If speaker is the same, append text to current group\n",
        "            else:\n",
        "                current_group['texts'].append(entry['text'].strip())\n",
        "        else:\n",
        "            # Speaker changed, save current group and start a new one\n",
        "            groups.append(current_group)\n",
        "            current_group = {\n",
        "                'speaker': entry['username'],\n",
        "                'start_time': entry['start'],\n",
        "                'end_time': entry['end'],\n",
        "                'texts': [entry['text'].strip()]\n",
        "            }\n",
        "\n",
        "    # Don’t forget to append the last group\n",
        "    if current_group is not None:\n",
        "        groups.append(current_group)\n",
        "\n",
        "    # Step 2: Format each group into transcript lines\n",
        "    transcript_lines = []\n",
        "    for i, group in enumerate(groups, 1):  # Start numbering at 1\n",
        "        # Convert the group's start time to HH:MM:SS format\n",
        "        start_time = datetime.fromisoformat(group['start_time']).strftime(\"%H:%M:%S\")\n",
        "        end_time = datetime.fromisoformat(group['end_time']).strftime(\"%H:%M:%S\")\n",
        "\n",
        "        # Format the entry: number, [user @ time], and all texts joined with spaces\n",
        "        # entry_text = f\"{i} [{group['speaker']} @ {start_time}]\\n{' '.join(group['texts'])}\\n\\n\"\n",
        "        if WebVTT:\n",
        "            entry_text = f\"{start_time} --> {end_time}\\n{group['speaker']}: {' '.join(group['texts'])}\\n\"\n",
        "        else:\n",
        "            entry_text = f\"{i} {group['speaker']} {start_time}\\n{' '.join(group['texts'])}\\n\\n\"\n",
        "\n",
        "        transcript_lines.append(entry_text)\n",
        "\n",
        "    # Step 3: Join all lines with newlines\n",
        "    return \"\\n\".join(transcript_lines)\n",
        "\n",
        "# ==============================================================================\n",
        "# Example usage with the rest of your code\n",
        "# Load JSON back into a Python object\n",
        "with open(unified_obj_path, 'r') as f:\n",
        "    unified_object = json.load(f)\n",
        "\n",
        "# Generate transcript\n",
        "transcript = json_to_text_transcript(unified_object, WebVTT=False)\n",
        "\n",
        "# Save transcript to file\n",
        "with open(final_transcript_path, 'w') as f:\n",
        "    f.write(transcript)\n",
        "\n",
        "# Print for verification\n",
        "print(f\"{CYAN}\\nTransformed transcript saved as 'transcript.txt':{RESET}\")\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "uY5BYIyijYqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657afd97-3141-45ec-d6f9-a00e06c75bd5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Transformed transcript saved as 'transcript.txt':\u001b[0m\n",
            "1 runfishrun 17:46:23\n",
            "Yeah, I don't know what's your stream on here.\n",
            "\n",
            "\n",
            "2 Unknown 17:46:27\n",
            "No, it's okay. Just working on the video, you know, trying to dissolve and put some sliders in a better position.\n",
            "\n",
            "\n",
            "3 runfishrun 17:46:39\n",
            "Yeah, so how is that going?\n",
            "\n",
            "\n",
            "4 Unknown 17:46:42\n",
            "I'm currently helping myself with ChatGPT due to it's new for me. But I'm seriously thinking to change a different program after this. Like that's the one and only project I'm doing with Canvas. It's like because when you have slides and then you have you make different slides in between those slides, there's a millisecond of a screen flicker which quickly flashes and like it's really making a weird behavior. So it's asking, it's telling me to dissolve in between with a little plus, but there is no plus. Like GPT tells me clearly there's a little plus, but that's what it is. Like, yeah. What are you working on?\n",
            "\n",
            "\n",
            "5 runfishrun 17:47:29\n",
            "Yeah, I just get this bot done. I also think about how to add like text to the video, like to make us to make it a mask or something like that to put it over there.\n",
            "\n",
            "\n",
            "6 Unknown 17:47:37\n",
            "Yes. Absolute.\n",
            "\n",
            "\n",
            "7 runfishrun 17:47:48\n",
            "This is gonna be difficult, I don't know.\n",
            "\n",
            "\n",
            "8 Unknown 17:47:51\n",
            "Canvas is usually very, very good with text over things. Like in the end, you can always put it in Canvas and you get a free month all the time. So once you use a free month Google, one account, you get a free month and the next month you take another account and have another free month. That's how I do it. This is my third account.\n",
            "\n",
            "\n",
            "9 runfishrun 17:48:13\n",
            "Okay, but you can do like how long can the videos be on Canvas\n",
            "\n",
            "\n",
            "10 Unknown 17:48:19\n",
            "I think with the pro version, you'd be good in any length, like because you get the free pro version literally for one month for free with this little life hack.\n",
            "\n",
            "\n",
            "11 runfishrun 17:48:32\n",
            "so Canvas is like really not just for ports, but also for long videos or what?\n",
            "\n",
            "\n",
            "12 Unknown 17:48:32\n",
            "But I definitely have to ask what's the microsign on size of a video on the canvas.\n",
            "\n",
            "\n",
            "13 runfishrun 17:48:49\n",
            "Okay, yeah, this is it's so much work.\n",
            "\n",
            "\n",
            "14 Unknown 17:48:57\n",
            "That's for real. But I'm assuming I think like my friend, we need someone that shows us sometimes little video editing, maybe with a woman with some social media skills.\n",
            "\n",
            "\n",
            "15 runfishrun 17:49:12\n",
            "Yeah.\n",
            "\n",
            "\n",
            "16 Unknown 17:49:12\n",
            "I mean, we have social media. It's just like some graphical that things go faster. It's not that we're not able to do it. I'm just feeling like sometimes I use too much time on my social media editing and trying. But it's not like I don't want to learn it.\n",
            "\n",
            "\n",
            "17 runfishrun 17:49:28\n",
            "Yeah.\n",
            "\n",
            "\n",
            "18 Unknown 17:49:29\n",
            "I really like it. But it's it says three to pro five gigabytes per video or up to one terabyte.\n",
            "\n",
            "\n",
            "19 runfishrun 17:49:45\n",
            "Up to one terabyte. So that's like uh four. Yeah, okay.\n",
            "\n",
            "\n",
            "20 Unknown 17:49:50\n",
            "The newer kind of super pro videos, yeah, for like the high-end HD videos.\n",
            "\n",
            "\n",
            "21 runfishrun 17:49:51\n",
            "I mean, that's\n",
            "\n",
            "\n",
            "22 Unknown 17:49:58\n",
            "It's probably not the one tool you want, but anything that has like I think like HD should be working.\n",
            "\n",
            "\n",
            "23 runfishrun 17:50:05\n",
            "yeah, uh, yeah, but not too long. I mean, if you have a normal HD movie like 1080, uh, two hours is about is at least four gigabytes.\n",
            "\n",
            "\n",
            "24 Unknown 17:50:16\n",
            "Yeah. Okay, that's a lot. But so you cannot make literally one hour to two hour videos on here, edit it and everything. That's definitely enough because Canvas is mostly used for like short videos or like titles and overlays on it. So once you're done, it has really cool features for like the text and elements.\n",
            "\n",
            "\n",
            "25 runfishrun 17:50:43\n",
            "Yeah, yeah, that's that's yeah, it's really good.\n",
            "\n",
            "\n",
            "26 Unknown 17:50:44\n",
            "Simple and free.\n",
            "\n",
            "\n",
            "27 runfishrun 17:50:48\n",
            "Uh, I'm really afraid that this is like too complicated with the tools that I'm using.\n",
            "\n",
            "\n",
            "28 Unknown 17:50:57\n",
            "That could be so in the end we just send it on Canva. And ChatGPT knows Canva very well for whatever reason. He's literally copy-pasting everything ready, telling you where to click. But right now I don't like ChatGPT Canva because it tells me there's a little plus here, which I can make it dissolve, but it's not happening.\n",
            "\n",
            "\n",
            "29 runfishrun 17:51:18\n",
            "Yeah, I know these kinds of situations. Uh, so in that case, but but you know exactly you cannot trust what it says. So, in this case, you can kind of go to perplexity or yeah, normally I just go to perplexity and then maybe to Google Gemini because Gemini can also have like this search function, and they just sometimes one model is just wrong. Sometimes one model is just particularly bad at something, then I just switch to another, and and and most and all the others they know it.\n",
            "\n",
            "\n",
            "30 Unknown 17:51:56\n",
            "Yeah, I don't know why it keeps looping. You're right. I'm gonna literally instantly ask Perplexity about help. Hey, are you a pro at video editing in Canvas? I need to slides. Yeah, and I'm like very excited about our future bot which takes a note because we have a lot of meetings and a lot of people have AI bots right now which make them even more meetings and so it will it will lead to that people need to take a lot of notes due to they have to be multiple places at the same time and this but will make life easy and I'm really looking forward to just also have fun with it like recording people in the call and instantly catching them for fake lies fake news just put them on the table\n",
            "\n",
            "\n",
            "31 runfishrun 17:52:52\n",
            "Yeah, I mean, we can just run this bot non-stop and make like how is how's this thing called uh URL hook or something? And then it and yeah, we can just like you know it's so yeah, it's it's not so expensive, and if this yeah, it's it's a super small model.\n",
            "\n",
            "\n",
            "32 Unknown 17:53:06\n",
            "yeah exactly in NHL\n",
            "\n",
            "\n",
            "33 runfishrun 17:53:16\n",
            "It's we could really to run this for the whole month always be accessible. I don't know, maybe this just like 30-40 US dollar.\n",
            "\n",
            "\n",
            "34 Unknown 17:53:27\n",
            "yes so it sends the transcript to NAN and from there on we're gonna transcribe it in an agent make a little task and send it through whatever through Notion back or whatever the client likes WhatsApp or so you you can get your little list or your little output in the analyzing tool yes for sure that like notion I read now about it today I didn't know it's a cool tool I need to try it out\n",
            "\n",
            "\n",
            "35 runfishrun 17:53:58\n",
            "Yeah, so the friends from Holland, they really they don't this guy, I mean the coach basically, he uh he doesn't like Notion, but I don't know why. Maybe he doesn't like it because uh he switched too many times between these tools and then he never he never got to Notion, you know, and now he's like this everybody tells him, Hey, Notion is so good, and he's just oh, I'm done with switching, and I think it's like that.\n",
            "\n",
            "\n",
            "36 Unknown 17:54:18\n",
            "yeah I'm closing yeah I know\n",
            "\n",
            "\n",
            "37 runfishrun 17:54:31\n",
            "And but but he is recommending like click up. I don't know if you notice.\n",
            "\n",
            "\n",
            "38 Unknown 17:54:37\n",
            "I think I used it one time heard about it but I can't really remember I haven't really I heard more about notion and let's see from implementation and now this is more the tool I would choose\n",
            "\n",
            "\n",
            "39 runfishrun 17:54:39\n",
            "Oh okay, yeah, yeah. Yeah, um, I don't know if if click up is is growing faster because they have like really cool features, but I never tried it, so I cannot. I think it's also it's paid mostly, so that's a problem.\n",
            "\n",
            "\n",
            "40 Unknown 17:55:16\n",
            "let's see I mean\n",
            "\n",
            "\n",
            "41 runfishrun 17:55:17\n",
            "It has like this calendar calendar and timeline and planning features, which are really, really good.\n",
            "\n",
            "\n",
            "42 Unknown 17:55:29\n",
            "meanwhile I realized that ChatGPT wasn't really a problem it was maybe still me I couldn't find it in LittleBetween so yeah there is a little plus button right a transition\n",
            "\n",
            "\n",
            "43 runfishrun 17:55:40\n",
            "Oh no, yeah, yeah, okay, we got it on tape, but it's so normal, man. It's it's just this happens to me all the time, too. Like, what is this AI output is wrong? And then 15 minutes later, damn, why didn't I follow it? It would write again. Yeah.\n",
            "\n",
            "\n",
            "44 Unknown 17:56:09\n",
            "yeah it is what it is we're learning we're learning what happened here and why the fuck is it different cuts now um ah this where is this came from whatever I'm learning\n",
            "\n",
            "\n",
            "45 runfishrun 17:56:13\n",
            "Yeah. Yeah. Okay.\n",
            "\n",
            "\n",
            "46 Unknown 17:56:30\n",
            "so we're gonna put me in\n",
            "\n",
            "\n",
            "47 runfishrun 17:56:37\n",
            "It's the analog work stop if it's got the extra transcriber in principle.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 💾 zip recordins_and_transcripts\n",
        "\n",
        "'''\n",
        "For downloads we zip it.\n",
        "(Google Colab doesn't support download and upload of directories.)\n",
        "'''\n",
        "from datetime import datetime\n",
        "# Get current date in yymmdd format\n",
        "current_date = datetime.now().strftime(\"%y%m%d\")\n",
        "\n",
        "# Create base zip filename with date prefix\n",
        "base_zip_filename = f\"{current_date}_recordings.zip\"\n",
        "\n",
        "# Check if file exists and add version number if needed\n",
        "i = 1\n",
        "zip_filename = base_zip_filename\n",
        "while os.path.exists(zip_filename):\n",
        "    zip_filename = f\"{current_date}_recordings_and_transcripts{i}.zip\"\n",
        "    i += 1\n",
        "\n",
        "# Zip the recordings directory with the dated filename\n",
        "!zip -r {zip_filename} recordings\n",
        "\n",
        "print(f\"{''}Created zip file: {zip_filename}{''}\")"
      ],
      "metadata": {
        "id": "eT4ZSwYYXsaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7f8fff-ef79-44a9-8a20-9ae14babbe9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: recordings/ (stored 0%)\n",
            "  adding: recordings/runfishrun/ (stored 0%)\n",
            "  adding: recordings/runfishrun/session_20250514_17M51_transcription.json (deflated 91%)\n",
            "  adding: recordings/runfishrun/session_20250514_17M51_cleaned.wav (deflated 70%)\n",
            "  adding: recordings/runfishrun/metadata.json (deflated 59%)\n",
            "  adding: recordings/runfishrun/session_20250514_17M51.wav (deflated 80%)\n",
            "  adding: recordings/runfishrun/session_20250514_17M51_transcription_adjusted.json (deflated 91%)\n",
            "  adding: recordings/unified_object.json (deflated 78%)\n",
            "  adding: recordings/transcript.txt (deflated 59%)\n",
            "  adding: recordings/Unknown/ (stored 0%)\n",
            "  adding: recordings/Unknown/session_20250514_17M51_transcription.json (deflated 91%)\n",
            "  adding: recordings/Unknown/session_20250514_17M51_cleaned.wav (deflated 56%)\n",
            "  adding: recordings/Unknown/metadata.json (deflated 59%)\n",
            "  adding: recordings/Unknown/session_20250514_17M51.wav (deflated 72%)\n",
            "  adding: recordings/Unknown/session_20250514_17M51_transcription_adjusted.json (deflated 91%)\n",
            "Created zip file: 250514_recordings_and_transcripts1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Bebugging: json_to_text_transcript ()\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Custom function to handle datetime serialization\n",
        "def custom_serializer(obj):\n",
        "    if isinstance(obj, datetime):\n",
        "        return obj.isoformat()  # Convert datetime to an ISO 8601 string\n",
        "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
        "\n",
        "# Save JSON with datetime converted to string\n",
        "with open('unified_object.json', 'w') as f:\n",
        "    json.dump(unified_object, f, indent=2, default=custom_serializer)\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Load JSON back into a Python object\n",
        "with open('unified_object.json', 'r') as f:\n",
        "    unified_object = json.load(f)\n",
        "\n",
        "\n",
        "# Transform to simplified transcript format\n",
        "def json_to_text_transcript(data):\n",
        "    transcript_lines = []\n",
        "    for i, entry in enumerate(data, 1):\n",
        "        # Convert start time to hh:mm:ss format\n",
        "        start_time = datetime.fromisoformat(entry[\"start\"]).strftime(\"%H:%M:%S\")\n",
        "        # Create entry with username and start time in header\n",
        "        entry_text = f\"{i}\\n\"\n",
        "        entry_text += f\"[{entry['username']} @ {start_time}]\\n\"\n",
        "        entry_text += f\"{entry['text'].strip()}\\n\"\n",
        "        transcript_lines.append(entry_text)\n",
        "    return \"\\n\".join(transcript_lines)\n",
        "\n",
        "# Generate transcript\n",
        "transcript = json_to_text_transcript(unified_object)\n",
        "\n",
        "# # Save transcript to file\n",
        "# with open('transcript.txt', 'w') as f:\n",
        "#     f.write(transcript)\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "zmUhzbhzycNb",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26475ed-3eb9-4e61-efff-2a454544be32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[runfishrun @ 17:46:23]\n",
            "Yeah, I don't know what's your stream on here.\n",
            "\n",
            "2\n",
            "[Unknown @ 17:46:27]\n",
            "No, it's okay.\n",
            "\n",
            "3\n",
            "[Unknown @ 17:46:28]\n",
            "Just working on the video, you know, trying to dissolve and put some sliders in a better position.\n",
            "\n",
            "4\n",
            "[runfishrun @ 17:46:39]\n",
            "Yeah, so how is that going?\n",
            "\n",
            "5\n",
            "[Unknown @ 17:46:42]\n",
            "I'm currently helping myself with ChatGPT due to it's new for me.\n",
            "\n",
            "6\n",
            "[Unknown @ 17:46:48]\n",
            "But I'm seriously thinking to change a different program after this.\n",
            "\n",
            "7\n",
            "[Unknown @ 17:46:52]\n",
            "Like that's the one and only project I'm doing with Canvas.\n",
            "\n",
            "8\n",
            "[Unknown @ 17:46:57]\n",
            "It's like because when you have slides and then you have you make different slides in between those slides, there's a millisecond of a screen flicker which quickly flashes and like it's really making a weird behavior.\n",
            "\n",
            "9\n",
            "[Unknown @ 17:47:14]\n",
            "So it's asking, it's telling me to dissolve in between with a little plus, but there is no plus.\n",
            "\n",
            "10\n",
            "[Unknown @ 17:47:21]\n",
            "Like GPT tells me clearly there's a little plus, but that's what it is.\n",
            "\n",
            "11\n",
            "[Unknown @ 17:47:26]\n",
            "Like, yeah.\n",
            "\n",
            "12\n",
            "[Unknown @ 17:47:27]\n",
            "What are you working on?\n",
            "\n",
            "13\n",
            "[runfishrun @ 17:47:29]\n",
            "Yeah, I just get this bot done.\n",
            "\n",
            "14\n",
            "[runfishrun @ 17:47:33]\n",
            "I also think about how to add like text to the video, like to make us to make it a mask or something like that to put it over there.\n",
            "\n",
            "15\n",
            "[Unknown @ 17:47:37]\n",
            "Yes.\n",
            "\n",
            "16\n",
            "[Unknown @ 17:47:45]\n",
            "Absolute.\n",
            "\n",
            "17\n",
            "[runfishrun @ 17:47:48]\n",
            "This is gonna be difficult, I don't know.\n",
            "\n",
            "18\n",
            "[Unknown @ 17:47:51]\n",
            "Canvas is usually very, very good with text over things.\n",
            "\n",
            "19\n",
            "[Unknown @ 17:47:56]\n",
            "Like in the end, you can always put it in Canvas and you get a free month all the time.\n",
            "\n",
            "20\n",
            "[Unknown @ 17:48:01]\n",
            "So once you use a free month Google, one account, you get a free month and the next month you take another account and have another free month.\n",
            "\n",
            "21\n",
            "[Unknown @ 17:48:10]\n",
            "That's how I do it.\n",
            "\n",
            "22\n",
            "[Unknown @ 17:48:11]\n",
            "This is my third account.\n",
            "\n",
            "23\n",
            "[runfishrun @ 17:48:13]\n",
            "Okay, but you can do like how long can the videos be on Canvas\n",
            "\n",
            "24\n",
            "[Unknown @ 17:48:19]\n",
            "I think with the pro version, you'd be good in any length, like because you get the free pro version literally for one month for free with this little life hack.\n",
            "\n",
            "25\n",
            "[runfishrun @ 17:48:32]\n",
            "so Canvas is like really not just for ports, but also for long videos or what?\n",
            "\n",
            "26\n",
            "[Unknown @ 17:48:32]\n",
            "But\n",
            "\n",
            "27\n",
            "[Unknown @ 17:48:38]\n",
            "I definitely have to ask what's the microsign on size of a video on the canvas.\n",
            "\n",
            "28\n",
            "[runfishrun @ 17:48:49]\n",
            "Okay, yeah, this is it's so much work.\n",
            "\n",
            "29\n",
            "[Unknown @ 17:48:57]\n",
            "That's for real.\n",
            "\n",
            "30\n",
            "[Unknown @ 17:48:58]\n",
            "But I'm assuming I think like my friend, we need someone that shows us sometimes little video editing, maybe with a woman with some social media skills.\n",
            "\n",
            "31\n",
            "[runfishrun @ 17:49:12]\n",
            "Yeah.\n",
            "\n",
            "32\n",
            "[Unknown @ 17:49:12]\n",
            "I mean, we have social media.\n",
            "\n",
            "33\n",
            "[Unknown @ 17:49:14]\n",
            "It's just like some graphical that things go faster.\n",
            "\n",
            "34\n",
            "[Unknown @ 17:49:18]\n",
            "It's not that we're not able to do it.\n",
            "\n",
            "35\n",
            "[Unknown @ 17:49:20]\n",
            "I'm just feeling like sometimes I use too much time on my social media editing and trying.\n",
            "\n",
            "36\n",
            "[Unknown @ 17:49:27]\n",
            "But it's not like I don't want to learn it.\n",
            "\n",
            "37\n",
            "[runfishrun @ 17:49:28]\n",
            "Yeah.\n",
            "\n",
            "38\n",
            "[Unknown @ 17:49:29]\n",
            "I really like it.\n",
            "\n",
            "39\n",
            "[Unknown @ 17:49:31]\n",
            "But it's it says three to pro five gigabytes per video or up to one terabyte.\n",
            "\n",
            "40\n",
            "[runfishrun @ 17:49:45]\n",
            "Up to one terabyte.\n",
            "\n",
            "41\n",
            "[runfishrun @ 17:49:46]\n",
            "So that's like uh four.\n",
            "\n",
            "42\n",
            "[runfishrun @ 17:49:49]\n",
            "Yeah, okay.\n",
            "\n",
            "43\n",
            "[Unknown @ 17:49:50]\n",
            "The newer kind of super pro videos, yeah, for like the high-end HD videos.\n",
            "\n",
            "44\n",
            "[runfishrun @ 17:49:51]\n",
            "I mean, that's\n",
            "\n",
            "45\n",
            "[Unknown @ 17:49:58]\n",
            "It's probably not the one tool you want, but anything that has like I think like HD should be working.\n",
            "\n",
            "46\n",
            "[runfishrun @ 17:50:05]\n",
            "yeah, uh, yeah, but not too long.\n",
            "\n",
            "47\n",
            "[runfishrun @ 17:50:10]\n",
            "I mean, if you have a normal HD movie like 1080, uh, two hours is about is at least four gigabytes.\n",
            "\n",
            "48\n",
            "[Unknown @ 17:50:16]\n",
            "Yeah.\n",
            "\n",
            "49\n",
            "[Unknown @ 17:50:21]\n",
            "Okay, that's a lot.\n",
            "\n",
            "50\n",
            "[Unknown @ 17:50:23]\n",
            "But so you cannot make literally one hour to two hour videos on here, edit it and everything.\n",
            "\n",
            "51\n",
            "[Unknown @ 17:50:28]\n",
            "That's definitely enough because Canvas is mostly used for like short videos or like titles and overlays on it.\n",
            "\n",
            "52\n",
            "[Unknown @ 17:50:36]\n",
            "So once you're done, it has really cool features for like the text and elements.\n",
            "\n",
            "53\n",
            "[runfishrun @ 17:50:43]\n",
            "Yeah, yeah, that's that's yeah, it's really good.\n",
            "\n",
            "54\n",
            "[Unknown @ 17:50:44]\n",
            "Simple and free.\n",
            "\n",
            "55\n",
            "[runfishrun @ 17:50:48]\n",
            "Uh, I'm really afraid that this is like too complicated with the tools that I'm using.\n",
            "\n",
            "56\n",
            "[Unknown @ 17:50:57]\n",
            "That could be so in the end we just send it on Canva.\n",
            "\n",
            "57\n",
            "[Unknown @ 17:51:01]\n",
            "And ChatGPT knows Canva very well for whatever reason.\n",
            "\n",
            "58\n",
            "[Unknown @ 17:51:04]\n",
            "He's literally copy-pasting everything ready, telling you where to click.\n",
            "\n",
            "59\n",
            "[Unknown @ 17:51:09]\n",
            "But right now I don't like ChatGPT Canva because it tells me there's a little plus here, which I can make it dissolve, but it's not happening.\n",
            "\n",
            "60\n",
            "[runfishrun @ 17:51:18]\n",
            "Yeah, I know these kinds of situations.\n",
            "\n",
            "61\n",
            "[runfishrun @ 17:51:21]\n",
            "Uh, so in that case, but but you know exactly you cannot trust what it says.\n",
            "\n",
            "62\n",
            "[runfishrun @ 17:51:27]\n",
            "So, in this case, you can kind of go to perplexity or yeah, normally I just go to perplexity and then maybe to Google Gemini because Gemini can also have like this search function, and they just sometimes one model is just wrong.\n",
            "\n",
            "63\n",
            "[runfishrun @ 17:51:46]\n",
            "Sometimes one model is just particularly bad at something, then I just switch to another, and and and most and all the others they know it.\n",
            "\n",
            "64\n",
            "[Unknown @ 17:51:56]\n",
            "Yeah, I don't know why it keeps looping.\n",
            "\n",
            "65\n",
            "[Unknown @ 17:51:59]\n",
            "You're right.\n",
            "\n",
            "66\n",
            "[Unknown @ 17:51:59]\n",
            "I'm gonna literally instantly ask Perplexity about help.\n",
            "\n",
            "67\n",
            "[Unknown @ 17:52:04]\n",
            "Hey, are you a pro at video editing in Canvas?\n",
            "\n",
            "68\n",
            "[Unknown @ 17:52:10]\n",
            "I need to slides.\n",
            "\n",
            "69\n",
            "[Unknown @ 17:52:17]\n",
            "Yeah, and I'm like very excited about our future bot which takes a note because we have a lot of meetings and a lot of people have AI bots right now which make them even more meetings and so it will it will lead to that people need to take a lot of notes due to they have to be multiple places at the same time and this but will make life easy and I'm really looking forward to just also have fun with it like recording people in the call and instantly catching them for fake lies fake news just put them on the table\n",
            "\n",
            "70\n",
            "[runfishrun @ 17:52:52]\n",
            "Yeah, I mean, we can just run this bot non-stop and make like how is how's this thing called uh URL hook or something?\n",
            "\n",
            "71\n",
            "[runfishrun @ 17:53:03]\n",
            "And then it and yeah, we can just like you know it's so yeah, it's it's not so expensive, and if this yeah, it's it's a super small model.\n",
            "\n",
            "72\n",
            "[Unknown @ 17:53:06]\n",
            "yeah exactly in NHL\n",
            "\n",
            "73\n",
            "[runfishrun @ 17:53:16]\n",
            "It's we could really to run this for the whole month always be accessible.\n",
            "\n",
            "74\n",
            "[runfishrun @ 17:53:22]\n",
            "I don't know, maybe this just like 30-40 US dollar.\n",
            "\n",
            "75\n",
            "[Unknown @ 17:53:27]\n",
            "yes so it sends the transcript to NAN and from there on we're gonna transcribe it in an agent make a little task and send it through whatever through Notion back or whatever the client likes WhatsApp or so you you can get your little list or your little output in the analyzing tool yes for sure that like notion I read now about it today I didn't know it's a cool tool I need to try it out\n",
            "\n",
            "76\n",
            "[runfishrun @ 17:53:58]\n",
            "Yeah, so the friends from Holland, they really they don't this guy, I mean the coach basically, he uh he doesn't like Notion, but I don't know why.\n",
            "\n",
            "77\n",
            "[runfishrun @ 17:54:12]\n",
            "Maybe he doesn't like it because uh he switched too many times between these tools and then he never he never got to Notion, you know, and now he's like this everybody tells him, Hey, Notion is so good, and he's just oh, I'm done with switching, and I think it's like that.\n",
            "\n",
            "78\n",
            "[Unknown @ 17:54:18]\n",
            "yeah\n",
            "\n",
            "79\n",
            "[Unknown @ 17:54:29]\n",
            "I'm closing yeah I know\n",
            "\n",
            "80\n",
            "[runfishrun @ 17:54:31]\n",
            "And but but he is recommending like click up.\n",
            "\n",
            "81\n",
            "[runfishrun @ 17:54:35]\n",
            "I don't know if you notice.\n",
            "\n",
            "82\n",
            "[Unknown @ 17:54:37]\n",
            "I think I used it one time heard about it but I can't really remember I haven't really I heard more about notion and let's see from implementation and now this is more the tool I would choose\n",
            "\n",
            "83\n",
            "[runfishrun @ 17:54:39]\n",
            "Oh okay, yeah, yeah.\n",
            "\n",
            "84\n",
            "[runfishrun @ 17:54:56]\n",
            "Yeah, um, I don't know if if click up is is growing faster because they have like really cool features, but I never tried it, so I cannot.\n",
            "\n",
            "85\n",
            "[runfishrun @ 17:55:10]\n",
            "I think it's also it's paid mostly, so that's a problem.\n",
            "\n",
            "86\n",
            "[Unknown @ 17:55:16]\n",
            "let's see I mean\n",
            "\n",
            "87\n",
            "[runfishrun @ 17:55:17]\n",
            "It has like this calendar calendar and timeline and planning features, which are really, really good.\n",
            "\n",
            "88\n",
            "[Unknown @ 17:55:29]\n",
            "meanwhile I realized that ChatGPT wasn't really a problem it was maybe still me I couldn't find it in LittleBetween so yeah there is a little plus button right a transition\n",
            "\n",
            "89\n",
            "[runfishrun @ 17:55:40]\n",
            "Oh no, yeah, yeah, okay, we got it on tape, but it's so normal, man.\n",
            "\n",
            "90\n",
            "[runfishrun @ 17:55:49]\n",
            "It's it's just this happens to me all the time, too.\n",
            "\n",
            "91\n",
            "[runfishrun @ 17:55:53]\n",
            "Like, what is this AI output is wrong?\n",
            "\n",
            "92\n",
            "[runfishrun @ 17:55:57]\n",
            "And then 15 minutes later, damn, why didn't I follow it?\n",
            "\n",
            "93\n",
            "[runfishrun @ 17:56:05]\n",
            "It would write again.\n",
            "\n",
            "94\n",
            "[runfishrun @ 17:56:09]\n",
            "Yeah.\n",
            "\n",
            "95\n",
            "[Unknown @ 17:56:09]\n",
            "yeah it is what it is we're learning we're learning what happened here and why the fuck is it different cuts now um ah this where is this came from whatever I'm learning\n",
            "\n",
            "96\n",
            "[runfishrun @ 17:56:13]\n",
            "Yeah.\n",
            "\n",
            "97\n",
            "[runfishrun @ 17:56:24]\n",
            "Yeah.\n",
            "\n",
            "98\n",
            "[runfishrun @ 17:56:27]\n",
            "Okay.\n",
            "\n",
            "99\n",
            "[Unknown @ 17:56:30]\n",
            "so we're gonna put me in\n",
            "\n",
            "100\n",
            "[runfishrun @ 17:56:37]\n",
            "It's the analog work stop if it's got the extra transcriber\n",
            "\n",
            "101\n",
            "[runfishrun @ 17:56:48]\n",
            "in principle.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}